{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c89dc09b-5737-4fc9-ac9c-10f2e478b444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  False\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  False\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.39it/s]\n",
      "Initialization, data:hotdog point:(1341362, 6)\n",
      "imagegt shape:  torch.Size([400, 400, 400, 3])\n",
      "Initialized point number:16096\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/hotdog/v2_0.012_0.015/msssimFalsedistsFalseedgesFalseadaptive_splattingrFalseadaptive_datarFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 loss:0.012 psnr:20.211\n",
      "-----eval-----  loss:0.007 psnr:21.593\n",
      "-----train-----  epoch:1 loss:0.007 psnr:22.723\n",
      "-----eval-----  loss:0.005 psnr:23.234\n",
      "-----train-----  epoch:2 loss:0.005 psnr:24.161\n",
      "-----eval-----  loss:0.004 psnr:24.298\n",
      "-----train-----  epoch:3 loss:0.005 psnr:25.045\n",
      "-----eval-----  loss:0.003 psnr:24.985\n",
      "-----train-----  epoch:4 loss:0.004 psnr:25.685\n",
      "-----eval-----  loss:0.003 psnr:25.524\n",
      "-----train-----  epoch:5 loss:0.004 psnr:26.176\n",
      "-----eval-----  loss:0.003 psnr:26.005\n",
      "-----train-----  epoch:6 loss:0.003 psnr:26.566\n",
      "-----eval-----  loss:0.002 psnr:26.338\n",
      "-----train-----  epoch:7 loss:0.003 psnr:26.865\n",
      "-----eval-----  loss:0.002 psnr:26.595\n",
      "-----train-----  epoch:8 loss:0.003 psnr:27.147\n",
      "-----eval-----  loss:0.002 psnr:26.852\n",
      "-----train-----  epoch:9 loss:0.003 psnr:27.346\n",
      "-----eval-----  loss:0.002 psnr:26.995\n",
      "-----train-----  epoch:10 loss:0.003 psnr:27.546\n",
      "-----eval-----  loss:0.002 psnr:27.177\n",
      "-----train-----  epoch:11 loss:0.003 psnr:27.705\n",
      "-----eval-----  loss:0.002 psnr:27.341\n",
      "-----train-----  epoch:12 loss:0.003 psnr:27.859\n",
      "-----eval-----  loss:0.002 psnr:27.443\n",
      "-----train-----  epoch:13 loss:0.003 psnr:27.987\n",
      "-----eval-----  loss:0.002 psnr:27.539\n",
      "-----train-----  epoch:14 loss:0.003 psnr:28.093\n",
      "-----eval-----  loss:0.002 psnr:27.691\n",
      "-----train-----  epoch:15 loss:0.002 psnr:28.215\n",
      "-----eval-----  loss:0.002 psnr:27.758\n",
      "-----train-----  epoch:16 loss:0.002 psnr:28.295\n",
      "-----eval-----  loss:0.002 psnr:27.843\n",
      "-----train-----  epoch:17 loss:0.002 psnr:28.399\n",
      "-----eval-----  loss:0.002 psnr:27.922\n",
      "-----train-----  epoch:18 loss:0.002 psnr:28.481\n",
      "-----eval-----  loss:0.002 psnr:27.979\n",
      "-----train-----  epoch:19 loss:0.002 psnr:28.567\n",
      "-----eval-----  loss:0.002 psnr:28.075\n",
      "-----train-----  epoch:0 loss:0.010 psnr:21.767\n",
      "-----eval-----  loss:0.003 psnr:24.734\n",
      "-----train-----  epoch:1 loss:0.004 psnr:25.824\n",
      "-----eval-----  loss:0.002 psnr:26.240\n",
      "-----train-----  epoch:2 loss:0.003 psnr:27.247\n",
      "-----eval-----  loss:0.002 psnr:27.620\n",
      "-----train-----  epoch:3 loss:0.003 psnr:28.198\n",
      "-----eval-----  loss:0.002 psnr:27.457\n",
      "-----train-----  epoch:4 loss:0.002 psnr:28.654\n",
      "-----eval-----  loss:0.001 psnr:28.490\n",
      "-----train-----  epoch:5 loss:0.002 psnr:29.221\n",
      "-----eval-----  loss:0.001 psnr:28.653\n",
      "-----train-----  epoch:6 loss:0.002 psnr:29.481\n",
      "-----eval-----  loss:0.001 psnr:29.238\n",
      "-----train-----  epoch:7 loss:0.002 psnr:29.902\n",
      "-----eval-----  loss:0.001 psnr:29.431\n",
      "-----train-----  epoch:8 loss:0.002 psnr:30.137\n",
      "-----eval-----  loss:0.001 psnr:29.785\n",
      "-----train-----  epoch:9 loss:0.002 psnr:30.511\n",
      "-----eval-----  loss:0.001 psnr:30.077\n",
      "-----train-----  epoch:10 loss:0.002 psnr:30.579\n",
      "-----eval-----  loss:0.001 psnr:30.037\n",
      "-----train-----  epoch:11 loss:0.002 psnr:30.742\n",
      "-----eval-----  loss:0.001 psnr:30.071\n",
      "-----train-----  epoch:12 loss:0.002 psnr:30.963\n",
      "-----eval-----  loss:0.001 psnr:30.363\n",
      "-----train-----  epoch:13 loss:0.002 psnr:31.101\n",
      "-----eval-----  loss:0.001 psnr:30.404\n",
      "-----train-----  epoch:14 loss:0.002 psnr:31.091\n",
      "-----eval-----  loss:0.001 psnr:30.638\n",
      "-----train-----  epoch:15 loss:0.002 psnr:31.230\n",
      "-----eval-----  loss:0.001 psnr:30.613\n",
      "-----train-----  epoch:16 loss:0.001 psnr:31.344\n",
      "-----eval-----  loss:0.001 psnr:30.687\n",
      "-----train-----  epoch:17 loss:0.001 psnr:31.478\n",
      "-----eval-----  loss:0.001 psnr:30.852\n",
      "-----train-----  epoch:18 loss:0.001 psnr:31.553\n",
      "-----eval-----  loss:0.001 psnr:30.863\n",
      "-----train-----  epoch:19 loss:0.001 psnr:31.659\n",
      "-----eval-----  loss:0.001 psnr:30.870\n",
      "-----train-----  epoch:20 loss:0.001 psnr:31.690\n",
      "-----eval-----  loss:0.001 psnr:30.890\n",
      "-----train-----  epoch:21 loss:0.001 psnr:31.743\n",
      "-----eval-----  loss:0.001 psnr:31.002\n",
      "-----train-----  epoch:22 loss:0.001 psnr:31.781\n",
      "-----eval-----  loss:0.001 psnr:30.989\n",
      "-----train-----  epoch:23 loss:0.001 psnr:31.871\n",
      "-----eval-----  loss:0.001 psnr:31.004\n",
      "-----train-----  epoch:24 loss:0.001 psnr:31.943\n",
      "-----eval-----  loss:0.001 psnr:31.122\n",
      "-----train-----  epoch:25 loss:0.001 psnr:31.941\n",
      "-----eval-----  loss:0.001 psnr:31.055\n",
      "-----train-----  epoch:26 loss:0.001 psnr:32.018\n",
      "-----eval-----  loss:0.001 psnr:31.092\n",
      "-----train-----  epoch:27 loss:0.001 psnr:32.038\n",
      "-----eval-----  loss:0.001 psnr:31.204\n",
      "-----train-----  epoch:28 loss:0.001 psnr:32.071\n",
      "-----eval-----  loss:0.001 psnr:31.218\n",
      "-----train-----  epoch:29 loss:0.001 psnr:32.116\n",
      "-----eval-----  loss:0.001 psnr:31.172\n",
      "-----train-----  epoch:0 loss:0.002 psnr:28.927\n",
      "-----eval-----  loss:0.001 psnr:29.596\n",
      "-----train-----  epoch:1 loss:0.002 psnr:30.671\n",
      "-----eval-----  loss:0.001 psnr:29.537\n",
      "-----train-----  epoch:2 loss:0.001 psnr:31.383\n",
      "-----eval-----  loss:0.001 psnr:31.271\n",
      "-----train-----  epoch:3 loss:0.001 psnr:31.588\n",
      "-----eval-----  loss:0.001 psnr:31.416\n",
      "-----train-----  epoch:4 loss:0.001 psnr:31.852\n",
      "-----eval-----  loss:0.001 psnr:31.460\n",
      "-----train-----  epoch:5 loss:0.001 psnr:31.589\n",
      "-----eval-----  loss:0.001 psnr:32.163\n",
      "-----train-----  epoch:6 loss:0.001 psnr:32.412\n",
      "-----eval-----  loss:0.001 psnr:32.386\n",
      "-----train-----  epoch:7 loss:0.001 psnr:32.686\n",
      "-----eval-----  loss:0.001 psnr:31.384\n",
      "-----train-----  epoch:8 loss:0.001 psnr:32.701\n",
      "-----eval-----  loss:0.001 psnr:31.899\n",
      "-----train-----  epoch:9 loss:0.001 psnr:32.895\n",
      "-----eval-----  loss:0.001 psnr:32.285\n",
      "-----train-----  epoch:10 loss:0.001 psnr:33.293\n",
      "-----eval-----  loss:0.001 psnr:32.920\n",
      "-----train-----  epoch:11 loss:0.001 psnr:33.578\n",
      "-----eval-----  loss:0.001 psnr:33.053\n",
      "-----train-----  epoch:12 loss:0.001 psnr:33.539\n",
      "-----eval-----  loss:0.001 psnr:32.585\n",
      "-----train-----  epoch:13 loss:0.001 psnr:33.633\n",
      "-----eval-----  loss:0.000 psnr:33.288\n",
      "-----train-----  epoch:14 loss:0.001 psnr:33.986\n",
      "-----eval-----  loss:0.000 psnr:33.370\n",
      "-----train-----  epoch:15 loss:0.001 psnr:34.103\n",
      "-----eval-----  loss:0.000 psnr:33.326\n",
      "-----train-----  epoch:16 loss:0.001 psnr:34.109\n",
      "-----eval-----  loss:0.000 psnr:33.565\n",
      "-----train-----  epoch:17 loss:0.001 psnr:34.272\n",
      "-----eval-----  loss:0.000 psnr:33.606\n",
      "-----train-----  epoch:18 loss:0.001 psnr:34.348\n",
      "-----eval-----  loss:0.000 psnr:33.663\n",
      "-----train-----  epoch:19 loss:0.001 psnr:34.377\n",
      "-----eval-----  loss:0.000 psnr:33.869\n",
      "-----train-----  epoch:20 loss:0.001 psnr:34.411\n",
      "-----eval-----  loss:0.000 psnr:33.513\n",
      "-----train-----  epoch:21 loss:0.001 psnr:34.580\n",
      "-----eval-----  loss:0.000 psnr:33.768\n",
      "-----train-----  epoch:22 loss:0.001 psnr:34.673\n",
      "-----eval-----  loss:0.000 psnr:33.770\n",
      "-----train-----  epoch:23 loss:0.001 psnr:34.696\n",
      "-----eval-----  loss:0.000 psnr:33.812\n",
      "-----train-----  epoch:24 loss:0.001 psnr:34.706\n",
      "-----eval-----  loss:0.000 psnr:33.963\n",
      "-----train-----  epoch:25 loss:0.001 psnr:34.826\n",
      "-----eval-----  loss:0.000 psnr:34.038\n",
      "-----train-----  epoch:26 loss:0.001 psnr:34.871\n",
      "-----eval-----  loss:0.000 psnr:34.055\n",
      "-----train-----  epoch:27 loss:0.001 psnr:34.920\n",
      "-----eval-----  loss:0.000 psnr:33.993\n",
      "-----train-----  epoch:28 loss:0.001 psnr:34.926\n",
      "-----eval-----  loss:0.000 psnr:34.124\n",
      "-----train-----  epoch:29 loss:0.001 psnr:34.963\n",
      "-----eval-----  loss:0.000 psnr:34.065\n",
      "-----train-----  epoch:0 loss:0.002 psnr:29.780\n",
      "-----eval-----  loss:0.001 psnr:30.102\n",
      "-----train-----  epoch:1 loss:0.002 psnr:30.645\n",
      "-----eval-----  loss:0.001 psnr:30.639\n",
      "-----train-----  epoch:2 loss:0.002 psnr:31.075\n",
      "-----eval-----  loss:0.001 psnr:30.475\n",
      "-----train-----  epoch:3 loss:0.001 psnr:31.524\n",
      "-----eval-----  loss:0.001 psnr:31.613\n",
      "-----train-----  epoch:4 loss:0.001 psnr:31.902\n",
      "-----eval-----  loss:0.001 psnr:31.410\n",
      "-----train-----  epoch:5 loss:0.001 psnr:32.280\n",
      "-----eval-----  loss:0.001 psnr:31.572\n",
      "-----train-----  epoch:6 loss:0.001 psnr:32.119\n",
      "-----eval-----  loss:0.001 psnr:31.409\n",
      "-----train-----  epoch:7 loss:0.001 psnr:32.236\n",
      "-----eval-----  loss:0.001 psnr:31.649\n",
      "-----train-----  epoch:8 loss:0.001 psnr:33.160\n",
      "-----eval-----  loss:0.001 psnr:32.648\n",
      "-----train-----  epoch:9 loss:0.001 psnr:33.522\n",
      "-----eval-----  loss:0.001 psnr:33.151\n",
      "-----train-----  epoch:10 loss:0.001 psnr:33.702\n",
      "-----eval-----  loss:0.001 psnr:33.059\n",
      "-----train-----  epoch:11 loss:0.001 psnr:34.023\n",
      "-----eval-----  loss:0.000 psnr:33.270\n",
      "-----train-----  epoch:12 loss:0.001 psnr:34.009\n",
      "-----eval-----  loss:0.000 psnr:33.711\n",
      "-----train-----  epoch:13 loss:0.001 psnr:34.229\n",
      "-----eval-----  loss:0.000 psnr:33.549\n",
      "-----train-----  epoch:14 loss:0.001 psnr:34.386\n",
      "-----eval-----  loss:0.000 psnr:33.678\n",
      "-----train-----  epoch:15 loss:0.001 psnr:34.508\n",
      "-----eval-----  loss:0.000 psnr:33.710\n",
      "-----train-----  epoch:16 loss:0.001 psnr:34.721\n",
      "-----eval-----  loss:0.000 psnr:33.796\n",
      "-----train-----  epoch:17 loss:0.001 psnr:34.867\n",
      "-----eval-----  loss:0.000 psnr:34.168\n",
      "-----train-----  epoch:18 loss:0.001 psnr:34.915\n",
      "-----eval-----  loss:0.000 psnr:34.074\n",
      "-----train-----  epoch:19 loss:0.001 psnr:34.947\n",
      "-----eval-----  loss:0.000 psnr:34.168\n",
      "-----train-----  epoch:20 loss:0.001 psnr:35.036\n",
      "-----eval-----  loss:0.000 psnr:34.385\n",
      "-----train-----  epoch:21 loss:0.001 psnr:35.155\n",
      "-----eval-----  loss:0.000 psnr:34.346\n",
      "-----train-----  epoch:22 loss:0.001 psnr:35.237\n",
      "-----eval-----  loss:0.000 psnr:34.166\n",
      "-----train-----  epoch:23 loss:0.001 psnr:35.252\n",
      "-----eval-----  loss:0.000 psnr:34.401\n",
      "-----train-----  epoch:24 loss:0.001 psnr:35.378\n",
      "-----eval-----  loss:0.000 psnr:34.490\n",
      "-----train-----  epoch:25 loss:0.001 psnr:35.462\n",
      "-----eval-----  loss:0.000 psnr:34.509\n",
      "-----train-----  epoch:26 loss:0.001 psnr:35.451\n",
      "-----eval-----  loss:0.000 psnr:34.593\n",
      "-----train-----  epoch:27 loss:0.001 psnr:35.543\n",
      "-----eval-----  loss:0.000 psnr:34.493\n",
      "-----train-----  epoch:28 loss:0.001 psnr:35.588\n",
      "-----eval-----  loss:0.000 psnr:34.506\n",
      "-----train-----  epoch:29 loss:0.001 psnr:35.626\n",
      "-----eval-----  loss:0.000 psnr:34.727\n",
      "-----eval-----  loss:0.000 psnr:34.728\n",
      "Training time: 218.07 s\n",
      "Rendering quality: 34.73 dB\n",
      "Rendering speed: 101.73 fps\n",
      "Model size: 7.30 MB\n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname hotdog --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.012 --splatting_r 0.015 --use_msssim False --use_dists False --use_edges False --adaptive_splattingr False --adaptive_datar False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b5d4bc6-74a1-4a36-8ae5-97647b159b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "Are we using adaptive splatting_r selection?  True\n",
      "Are we using adaptive adaptive_datar selection?  True\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.39it/s]\n",
      "Initialization, data:hotdog point:(1341362, 6)\n",
      "imagegt shape:  torch.Size([400, 400, 400, 3])\n",
      "Using splatting_r:  0.010804999619722366\n",
      "Using data_r:  0.36016665399074554\n",
      "Initialized point number:483113\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/hotdog/v2_0.012_0.015/msssimTruedistsFalseedgesTrueadaptive_splattingrTrueadaptive_datarTrue\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 edge_loss:3539.500 psnr:23.882\n",
      "-----eval-----  loss:7144.001 psnr:24.674\n",
      "-----train-----  epoch:1 edge_loss:3483.470 psnr:25.571\n",
      "-----eval-----  loss:6776.421 psnr:25.629\n",
      "-----train-----  epoch:2 edge_loss:3301.520 psnr:26.387\n",
      "-----eval-----  loss:6398.413 psnr:26.226\n",
      "-----train-----  epoch:3 edge_loss:3138.120 psnr:26.944\n",
      "-----eval-----  loss:6210.147 psnr:26.685\n",
      "-----train-----  epoch:4 edge_loss:3072.570 psnr:27.364\n",
      "-----eval-----  loss:6089.361 psnr:27.088\n",
      "-----train-----  epoch:5 edge_loss:2977.030 psnr:27.711\n",
      "-----eval-----  loss:5818.749 psnr:27.413\n",
      "-----train-----  epoch:6 edge_loss:2896.290 psnr:27.986\n",
      "-----eval-----  loss:5867.354 psnr:27.693\n",
      "-----train-----  epoch:7 edge_loss:2866.340 psnr:28.207\n",
      "-----eval-----  loss:5766.830 psnr:27.883\n",
      "-----train-----  epoch:8 edge_loss:2801.240 psnr:28.450\n",
      "-----eval-----  loss:5596.655 psnr:28.072\n",
      "-----train-----  epoch:9 edge_loss:2744.680 psnr:28.614\n",
      "-----eval-----  loss:5480.914 psnr:28.220\n",
      "-----train-----  epoch:10 edge_loss:2723.450 psnr:28.785\n",
      "-----eval-----  loss:5473.609 psnr:28.331\n",
      "-----train-----  epoch:11 edge_loss:2686.640 psnr:28.896\n",
      "-----eval-----  loss:5431.173 psnr:28.476\n",
      "-----train-----  epoch:12 edge_loss:2657.580 psnr:29.009\n",
      "-----eval-----  loss:5509.694 psnr:28.535\n",
      "-----train-----  epoch:13 edge_loss:2664.670 psnr:29.082\n",
      "-----eval-----  loss:5386.389 psnr:28.638\n",
      "-----train-----  epoch:14 edge_loss:2621.320 psnr:29.171\n",
      "-----eval-----  loss:5373.605 psnr:28.721\n",
      "-----train-----  epoch:15 edge_loss:2590.040 psnr:29.259\n",
      "-----eval-----  loss:5444.909 psnr:28.785\n",
      "-----train-----  epoch:16 edge_loss:2591.810 psnr:29.314\n",
      "-----eval-----  loss:5400.735 psnr:28.813\n",
      "-----train-----  epoch:17 edge_loss:2588.130 psnr:29.374\n",
      "-----eval-----  loss:5363.952 psnr:28.883\n",
      "-----train-----  epoch:18 edge_loss:2576.960 psnr:29.428\n",
      "-----eval-----  loss:5369.865 psnr:28.935\n",
      "-----train-----  epoch:19 edge_loss:2566.700 psnr:29.480\n",
      "-----eval-----  loss:5309.517 psnr:28.980\n",
      "-----train-----  epoch:0 edge_loss:13048.460 psnr:19.507\n",
      "-----eval-----  loss:25130.215 psnr:21.080\n",
      "-----train-----  epoch:1 edge_loss:11233.460 psnr:21.801\n",
      "-----eval-----  loss:22248.459 psnr:22.137\n",
      "-----train-----  epoch:2 edge_loss:10054.479 psnr:22.786\n",
      "-----eval-----  loss:19939.492 psnr:22.959\n",
      "-----train-----  epoch:3 edge_loss:9033.260 psnr:23.534\n",
      "-----eval-----  loss:19295.746 psnr:23.506\n",
      "-----train-----  epoch:4 edge_loss:8915.270 psnr:23.889\n",
      "-----eval-----  loss:17260.262 psnr:24.027\n",
      "-----train-----  epoch:5 edge_loss:8184.340 psnr:24.411\n",
      "-----eval-----  loss:20150.967 psnr:24.092\n",
      "-----train-----  epoch:6 edge_loss:7817.170 psnr:24.721\n",
      "-----eval-----  loss:15377.729 psnr:24.815\n",
      "-----train-----  epoch:7 edge_loss:6715.680 psnr:25.257\n",
      "-----eval-----  loss:14368.422 psnr:25.183\n",
      "-----train-----  epoch:8 edge_loss:6236.870 psnr:25.589\n",
      "-----eval-----  loss:14084.507 psnr:25.477\n",
      "-----train-----  epoch:9 edge_loss:5576.840 psnr:26.000\n",
      "-----eval-----  loss:10007.359 psnr:26.082\n",
      "-----train-----  epoch:10 edge_loss:5056.280 psnr:26.334\n",
      "-----eval-----  loss:10115.707 psnr:26.231\n",
      "-----train-----  epoch:11 edge_loss:4527.410 psnr:26.660\n",
      "-----eval-----  loss:9672.575 psnr:26.482\n",
      "-----train-----  epoch:12 edge_loss:4065.500 psnr:26.978\n",
      "-----eval-----  loss:8269.004 psnr:26.912\n",
      "-----train-----  epoch:13 edge_loss:3606.870 psnr:27.335\n",
      "-----eval-----  loss:7456.391 psnr:27.211\n",
      "-----train-----  epoch:14 edge_loss:3539.300 psnr:27.516\n",
      "-----eval-----  loss:7451.434 psnr:27.377\n",
      "-----train-----  epoch:15 edge_loss:3410.180 psnr:27.674\n",
      "-----eval-----  loss:7273.607 psnr:27.472\n",
      "-----train-----  epoch:16 edge_loss:3114.150 psnr:27.939\n",
      "-----eval-----  loss:6797.518 psnr:27.728\n",
      "-----train-----  epoch:17 edge_loss:2914.450 psnr:28.165\n",
      "-----eval-----  loss:6162.992 psnr:27.946\n",
      "-----train-----  epoch:18 edge_loss:2751.980 psnr:28.379\n",
      "-----eval-----  loss:6298.298 psnr:28.082\n",
      "-----train-----  epoch:19 edge_loss:2599.790 psnr:28.573\n",
      "-----eval-----  loss:5971.338 psnr:28.268\n",
      "-----train-----  epoch:20 edge_loss:2521.310 psnr:28.785\n",
      "-----eval-----  loss:5696.033 psnr:28.438\n",
      "-----train-----  epoch:21 edge_loss:2430.920 psnr:28.937\n",
      "-----eval-----  loss:5571.597 psnr:28.598\n",
      "-----train-----  epoch:22 edge_loss:2377.780 psnr:29.130\n",
      "-----eval-----  loss:5497.162 psnr:28.786\n",
      "-----train-----  epoch:23 edge_loss:2295.050 psnr:29.425\n",
      "-----eval-----  loss:5399.856 psnr:29.115\n",
      "-----train-----  epoch:24 edge_loss:2261.860 psnr:29.749\n",
      "-----eval-----  loss:5386.291 psnr:29.303\n",
      "-----train-----  epoch:25 edge_loss:2217.900 psnr:29.942\n",
      "-----eval-----  loss:5344.204 psnr:29.399\n",
      "-----train-----  epoch:26 edge_loss:2158.480 psnr:30.104\n",
      "-----eval-----  loss:5193.333 psnr:29.536\n",
      "-----train-----  epoch:27 edge_loss:2095.270 psnr:30.234\n",
      "-----eval-----  loss:5079.854 psnr:29.630\n",
      "-----train-----  epoch:28 edge_loss:2065.180 psnr:30.297\n",
      "-----eval-----  loss:5052.375 psnr:29.709\n",
      "-----train-----  epoch:29 edge_loss:2027.370 psnr:30.424\n",
      "-----eval-----  loss:4943.940 psnr:29.735\n",
      "-----train-----  epoch:0 edge_loss:10446.840 psnr:24.611\n",
      "-----eval-----  loss:21882.098 psnr:24.752\n",
      "-----train-----  epoch:1 edge_loss:9255.729 psnr:25.653\n",
      "-----eval-----  loss:20397.486 psnr:25.020\n",
      "-----train-----  epoch:2 edge_loss:7780.250 psnr:26.323\n",
      "-----eval-----  loss:16256.856 psnr:26.091\n",
      "-----train-----  epoch:3 edge_loss:7555.770 psnr:26.558\n",
      "-----eval-----  loss:14713.372 psnr:26.505\n",
      "-----train-----  epoch:4 edge_loss:6626.930 psnr:27.081\n",
      "-----eval-----  loss:13147.280 psnr:26.837\n",
      "-----train-----  epoch:5 edge_loss:7004.720 psnr:27.093\n",
      "-----eval-----  loss:11311.533 psnr:27.445\n",
      "-----train-----  epoch:6 edge_loss:5883.080 psnr:27.719\n",
      "-----eval-----  loss:9928.137 psnr:27.817\n",
      "-----train-----  epoch:7 edge_loss:5191.250 psnr:28.130\n",
      "-----eval-----  loss:13496.238 psnr:27.255\n",
      "-----train-----  epoch:8 edge_loss:5112.370 psnr:28.314\n",
      "-----eval-----  loss:10726.749 psnr:27.882\n",
      "-----train-----  epoch:9 edge_loss:4744.330 psnr:28.617\n",
      "-----eval-----  loss:9546.658 psnr:28.181\n",
      "-----train-----  epoch:10 edge_loss:4020.000 psnr:29.051\n",
      "-----eval-----  loss:7864.650 psnr:28.798\n",
      "-----train-----  epoch:11 edge_loss:3435.440 psnr:29.460\n",
      "-----eval-----  loss:7634.476 psnr:28.947\n",
      "-----train-----  epoch:12 edge_loss:3401.360 psnr:29.563\n",
      "-----eval-----  loss:8270.565 psnr:28.848\n",
      "-----train-----  epoch:13 edge_loss:3248.260 psnr:29.756\n",
      "-----eval-----  loss:6303.688 psnr:29.428\n",
      "-----train-----  epoch:14 edge_loss:2735.070 psnr:30.141\n",
      "-----eval-----  loss:5816.815 psnr:29.654\n",
      "-----train-----  epoch:15 edge_loss:2601.280 psnr:30.333\n",
      "-----eval-----  loss:5681.075 psnr:29.754\n",
      "-----train-----  epoch:16 edge_loss:2577.100 psnr:30.424\n",
      "-----eval-----  loss:5481.074 psnr:29.897\n",
      "-----train-----  epoch:17 edge_loss:2331.150 psnr:30.674\n",
      "-----eval-----  loss:5316.726 psnr:30.008\n",
      "-----train-----  epoch:18 edge_loss:2213.020 psnr:30.800\n",
      "-----eval-----  loss:4798.288 psnr:30.245\n",
      "-----train-----  epoch:19 edge_loss:2153.930 psnr:30.941\n",
      "-----eval-----  loss:4821.331 psnr:30.293\n",
      "-----train-----  epoch:20 edge_loss:2133.000 psnr:30.968\n",
      "-----eval-----  loss:4956.376 psnr:30.222\n",
      "-----train-----  epoch:21 edge_loss:2007.030 psnr:31.153\n",
      "-----eval-----  loss:4637.852 psnr:30.442\n",
      "-----train-----  epoch:22 edge_loss:1945.240 psnr:31.269\n",
      "-----eval-----  loss:4558.547 psnr:30.512\n",
      "-----train-----  epoch:23 edge_loss:1893.980 psnr:31.376\n",
      "-----eval-----  loss:4437.416 psnr:30.601\n",
      "-----train-----  epoch:24 edge_loss:1865.960 psnr:31.422\n",
      "-----eval-----  loss:4328.545 psnr:30.722\n",
      "-----train-----  epoch:25 edge_loss:1806.840 psnr:31.511\n",
      "-----eval-----  loss:4324.371 psnr:30.760\n",
      "-----train-----  epoch:26 edge_loss:1773.110 psnr:31.605\n",
      "-----eval-----  loss:4192.718 psnr:30.820\n",
      "-----train-----  epoch:27 edge_loss:1738.590 psnr:31.695\n",
      "-----eval-----  loss:4245.936 psnr:30.838\n",
      "-----train-----  epoch:28 edge_loss:1720.020 psnr:31.729\n",
      "-----eval-----  loss:4098.370 psnr:30.939\n",
      "-----train-----  epoch:29 edge_loss:1694.200 psnr:31.776\n",
      "-----eval-----  loss:4124.370 psnr:30.944\n",
      "-----train-----  epoch:0 edge_loss:10061.779 psnr:25.516\n",
      "-----eval-----  loss:18426.426 psnr:25.760\n",
      "-----train-----  epoch:1 edge_loss:8721.710 psnr:26.261\n",
      "-----eval-----  loss:16712.770 psnr:26.102\n",
      "-----train-----  epoch:2 edge_loss:7970.510 psnr:26.686\n",
      "-----eval-----  loss:17875.902 psnr:26.178\n",
      "-----train-----  epoch:3 edge_loss:7210.400 psnr:27.123\n",
      "-----eval-----  loss:13824.410 psnr:27.108\n",
      "-----train-----  epoch:4 edge_loss:6561.000 psnr:27.516\n",
      "-----eval-----  loss:14634.674 psnr:27.068\n",
      "-----train-----  epoch:5 edge_loss:6202.320 psnr:27.855\n",
      "-----eval-----  loss:12610.493 psnr:27.493\n",
      "-----train-----  epoch:6 edge_loss:6289.970 psnr:27.867\n",
      "-----eval-----  loss:15217.111 psnr:26.984\n",
      "-----train-----  epoch:7 edge_loss:5908.030 psnr:28.092\n",
      "-----eval-----  loss:12922.496 psnr:27.698\n",
      "-----train-----  epoch:8 edge_loss:4606.180 psnr:28.876\n",
      "-----eval-----  loss:9591.265 psnr:28.550\n",
      "-----train-----  epoch:9 edge_loss:4054.160 psnr:29.341\n",
      "-----eval-----  loss:7378.908 psnr:29.158\n",
      "-----train-----  epoch:10 edge_loss:3562.690 psnr:29.704\n",
      "-----eval-----  loss:7857.347 psnr:29.145\n",
      "-----train-----  epoch:11 edge_loss:3179.860 psnr:30.065\n",
      "-----eval-----  loss:7058.038 psnr:29.455\n",
      "-----train-----  epoch:12 edge_loss:2958.730 psnr:30.273\n",
      "-----eval-----  loss:5662.467 psnr:29.956\n",
      "-----train-----  epoch:13 edge_loss:2812.540 psnr:30.475\n",
      "-----eval-----  loss:6133.686 psnr:29.879\n",
      "-----train-----  epoch:14 edge_loss:2655.220 psnr:30.676\n",
      "-----eval-----  loss:5768.031 psnr:30.030\n",
      "-----train-----  epoch:15 edge_loss:2429.590 psnr:30.862\n",
      "-----eval-----  loss:5343.335 psnr:30.206\n",
      "-----train-----  epoch:16 edge_loss:2217.510 psnr:31.125\n",
      "-----eval-----  loss:4906.463 psnr:30.470\n",
      "-----train-----  epoch:17 edge_loss:2086.530 psnr:31.292\n",
      "-----eval-----  loss:4590.375 psnr:30.656\n",
      "-----train-----  epoch:18 edge_loss:2016.500 psnr:31.386\n",
      "-----eval-----  loss:4593.678 psnr:30.687\n",
      "-----train-----  epoch:19 edge_loss:1931.330 psnr:31.557\n",
      "-----eval-----  loss:4429.241 psnr:30.897\n",
      "-----train-----  epoch:20 edge_loss:1878.060 psnr:31.652\n",
      "-----eval-----  loss:4158.544 psnr:31.037\n",
      "-----train-----  epoch:21 edge_loss:1792.150 psnr:31.759\n",
      "-----eval-----  loss:4174.892 psnr:31.085\n",
      "-----train-----  epoch:22 edge_loss:1747.180 psnr:31.881\n",
      "-----eval-----  loss:4131.849 psnr:31.086\n",
      "-----train-----  epoch:23 edge_loss:1726.940 psnr:31.937\n",
      "-----eval-----  loss:4016.021 psnr:31.217\n",
      "-----train-----  epoch:24 edge_loss:1653.720 psnr:32.069\n",
      "-----eval-----  loss:3899.760 psnr:31.326\n",
      "-----train-----  epoch:25 edge_loss:1629.120 psnr:32.154\n",
      "-----eval-----  loss:3842.542 psnr:31.368\n",
      "-----train-----  epoch:26 edge_loss:1613.710 psnr:32.208\n",
      "-----eval-----  loss:3803.672 psnr:31.468\n",
      "-----train-----  epoch:27 edge_loss:1574.270 psnr:32.288\n",
      "-----eval-----  loss:3874.368 psnr:31.459\n",
      "-----train-----  epoch:28 edge_loss:1566.880 psnr:32.347\n",
      "-----eval-----  loss:3848.803 psnr:31.479\n",
      "-----train-----  epoch:29 edge_loss:1534.590 psnr:32.395\n",
      "-----eval-----  loss:3701.845 psnr:31.574\n",
      "-----eval-----  loss:3701.845 psnr:31.574\n",
      "Training time: 1904.66 s\n",
      "Rendering quality: 31.57 dB\n",
      "Rendering speed: 12.87 fps\n",
      "Model size: 89.59 MB\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname hotdog --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.012 --splatting_r 0.015 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr True --adaptive_datar True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400eaa9-8d32-4344-9a73-d377ed129d09",
   "metadata": {},
   "source": [
    "# MS-SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d05379-63df-4248-9572-09ebfb0ca451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.40it/s]\n",
      "Initialization, data:hotdog point:(1341362, 6)\n",
      "Initialized point number:16096\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/hotdog/v2_0.012_0.015/msssimTruedistsFalseedgesFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 loss:0.186 psnr:19.958\n",
      "-----eval-----  loss:0.136 psnr:21.096\n",
      "-----train-----  epoch:1 loss:0.114 psnr:21.972\n",
      "-----eval-----  loss:0.106 psnr:22.428\n",
      "-----train-----  epoch:2 loss:0.092 psnr:23.076\n",
      "-----eval-----  loss:0.091 psnr:23.266\n",
      "-----train-----  epoch:3 loss:0.081 psnr:23.773\n",
      "-----eval-----  loss:0.082 psnr:23.856\n",
      "-----train-----  epoch:4 loss:0.073 psnr:24.303\n",
      "-----eval-----  loss:0.075 psnr:24.311\n",
      "-----train-----  epoch:5 loss:0.067 psnr:24.736\n",
      "-----eval-----  loss:0.069 psnr:24.689\n",
      "-----train-----  epoch:6 loss:0.062 psnr:25.065\n",
      "-----eval-----  loss:0.065 psnr:24.956\n",
      "-----train-----  epoch:7 loss:0.059 psnr:25.315\n",
      "-----eval-----  loss:0.062 psnr:25.182\n",
      "-----train-----  epoch:8 loss:0.056 psnr:25.556\n",
      "-----eval-----  loss:0.059 psnr:25.393\n",
      "-----train-----  epoch:9 loss:0.054 psnr:25.750\n",
      "-----eval-----  loss:0.057 psnr:25.511\n",
      "-----train-----  epoch:10 loss:0.051 psnr:25.914\n",
      "-----eval-----  loss:0.055 psnr:25.670\n",
      "-----train-----  epoch:11 loss:0.050 psnr:26.053\n",
      "-----eval-----  loss:0.054 psnr:25.787\n",
      "-----train-----  epoch:12 loss:0.048 psnr:26.161\n",
      "-----eval-----  loss:0.053 psnr:25.875\n",
      "-----train-----  epoch:13 loss:0.047 psnr:26.274\n",
      "-----eval-----  loss:0.051 psnr:25.967\n",
      "-----train-----  epoch:14 loss:0.046 psnr:26.361\n",
      "-----eval-----  loss:0.050 psnr:26.076\n",
      "-----train-----  epoch:15 loss:0.045 psnr:26.469\n",
      "-----eval-----  loss:0.049 psnr:26.145\n",
      "-----train-----  epoch:16 loss:0.044 psnr:26.536\n",
      "-----eval-----  loss:0.048 psnr:26.198\n",
      "-----train-----  epoch:17 loss:0.043 psnr:26.629\n",
      "-----eval-----  loss:0.047 psnr:26.290\n",
      "-----train-----  epoch:18 loss:0.042 psnr:26.695\n",
      "-----eval-----  loss:0.047 psnr:26.339\n",
      "-----train-----  epoch:19 loss:0.042 psnr:26.767\n",
      "-----eval-----  loss:0.046 psnr:26.411\n",
      "-----train-----  epoch:0 loss:0.149 psnr:20.290\n",
      "-----eval-----  loss:0.107 psnr:22.383\n",
      "-----train-----  epoch:1 loss:0.097 psnr:22.986\n",
      "-----eval-----  loss:0.090 psnr:23.523\n",
      "-----train-----  epoch:2 loss:0.081 psnr:24.037\n",
      "-----eval-----  loss:0.081 psnr:24.280\n",
      "-----train-----  epoch:3 loss:0.072 psnr:24.706\n",
      "-----eval-----  loss:0.075 psnr:24.824\n",
      "-----train-----  epoch:4 loss:0.070 psnr:25.090\n",
      "-----eval-----  loss:0.068 psnr:25.236\n",
      "-----train-----  epoch:5 loss:0.064 psnr:25.515\n",
      "-----eval-----  loss:0.075 psnr:25.349\n",
      "-----train-----  epoch:6 loss:0.060 psnr:25.859\n",
      "-----eval-----  loss:0.060 psnr:25.915\n",
      "-----train-----  epoch:7 loss:0.054 psnr:26.248\n",
      "-----eval-----  loss:0.058 psnr:26.232\n",
      "-----train-----  epoch:8 loss:0.052 psnr:26.561\n",
      "-----eval-----  loss:0.058 psnr:26.375\n",
      "-----train-----  epoch:9 loss:0.047 psnr:26.866\n",
      "-----eval-----  loss:0.046 psnr:26.765\n",
      "-----train-----  epoch:10 loss:0.044 psnr:27.051\n",
      "-----eval-----  loss:0.045 psnr:26.919\n",
      "-----train-----  epoch:11 loss:0.041 psnr:27.270\n",
      "-----eval-----  loss:0.046 psnr:27.071\n",
      "-----train-----  epoch:12 loss:0.039 psnr:27.485\n",
      "-----eval-----  loss:0.041 psnr:27.298\n",
      "-----train-----  epoch:13 loss:0.035 psnr:27.699\n",
      "-----eval-----  loss:0.038 psnr:27.458\n",
      "-----train-----  epoch:14 loss:0.034 psnr:27.773\n",
      "-----eval-----  loss:0.037 psnr:27.597\n",
      "-----train-----  epoch:15 loss:0.034 psnr:27.879\n",
      "-----eval-----  loss:0.037 psnr:27.642\n",
      "-----train-----  epoch:16 loss:0.031 psnr:28.034\n",
      "-----eval-----  loss:0.035 psnr:27.776\n",
      "-----train-----  epoch:17 loss:0.030 psnr:28.166\n",
      "-----eval-----  loss:0.032 psnr:27.916\n",
      "-----train-----  epoch:18 loss:0.029 psnr:28.283\n",
      "-----eval-----  loss:0.033 psnr:27.974\n",
      "-----train-----  epoch:19 loss:0.028 psnr:28.368\n",
      "-----eval-----  loss:0.032 psnr:28.069\n",
      "-----train-----  epoch:20 loss:0.027 psnr:28.474\n",
      "-----eval-----  loss:0.031 psnr:28.150\n",
      "-----train-----  epoch:21 loss:0.026 psnr:28.533\n",
      "-----eval-----  loss:0.030 psnr:28.206\n",
      "-----train-----  epoch:22 loss:0.026 psnr:28.600\n",
      "-----eval-----  loss:0.030 psnr:28.264\n",
      "-----train-----  epoch:23 loss:0.025 psnr:28.664\n",
      "-----eval-----  loss:0.029 psnr:28.341\n",
      "-----train-----  epoch:24 loss:0.024 psnr:28.772\n",
      "-----eval-----  loss:0.029 psnr:28.380\n",
      "-----train-----  epoch:25 loss:0.024 psnr:28.795\n",
      "-----eval-----  loss:0.029 psnr:28.432\n",
      "-----train-----  epoch:26 loss:0.023 psnr:28.860\n",
      "-----eval-----  loss:0.028 psnr:28.495\n",
      "-----train-----  epoch:27 loss:0.023 psnr:28.931\n",
      "-----eval-----  loss:0.028 psnr:28.522\n",
      "-----train-----  epoch:28 loss:0.023 psnr:28.956\n",
      "-----eval-----  loss:0.027 psnr:28.576\n",
      "-----train-----  epoch:29 loss:0.022 psnr:28.995\n",
      "-----eval-----  loss:0.027 psnr:28.596\n",
      "-----train-----  epoch:0 loss:0.073 psnr:26.231\n",
      "-----eval-----  loss:0.075 psnr:26.686\n",
      "-----train-----  epoch:1 loss:0.059 psnr:27.516\n",
      "-----eval-----  loss:0.073 psnr:26.996\n",
      "-----train-----  epoch:2 loss:0.049 psnr:28.258\n",
      "-----eval-----  loss:0.052 psnr:28.182\n",
      "-----train-----  epoch:3 loss:0.048 psnr:28.506\n",
      "-----eval-----  loss:0.046 psnr:28.669\n",
      "-----train-----  epoch:4 loss:0.041 psnr:28.983\n",
      "-----eval-----  loss:0.041 psnr:29.077\n",
      "-----train-----  epoch:5 loss:0.045 psnr:28.865\n",
      "-----eval-----  loss:0.035 psnr:29.543\n",
      "-----train-----  epoch:6 loss:0.037 psnr:29.488\n",
      "-----eval-----  loss:0.031 psnr:29.887\n",
      "-----train-----  epoch:7 loss:0.033 psnr:29.847\n",
      "-----eval-----  loss:0.046 psnr:29.130\n",
      "-----train-----  epoch:8 loss:0.034 psnr:29.901\n",
      "-----eval-----  loss:0.036 psnr:29.725\n",
      "-----train-----  epoch:9 loss:0.032 psnr:30.131\n",
      "-----eval-----  loss:0.032 psnr:30.094\n",
      "-----train-----  epoch:10 loss:0.027 psnr:30.521\n",
      "-----eval-----  loss:0.025 psnr:30.698\n",
      "-----train-----  epoch:11 loss:0.023 psnr:30.918\n",
      "-----eval-----  loss:0.025 psnr:30.777\n",
      "-----train-----  epoch:12 loss:0.022 psnr:30.976\n",
      "-----eval-----  loss:0.029 psnr:30.606\n",
      "-----train-----  epoch:13 loss:0.021 psnr:31.081\n",
      "-----eval-----  loss:0.022 psnr:31.145\n",
      "-----train-----  epoch:14 loss:0.018 psnr:31.435\n",
      "-----eval-----  loss:0.019 psnr:31.366\n",
      "-----train-----  epoch:15 loss:0.017 psnr:31.605\n",
      "-----eval-----  loss:0.018 psnr:31.439\n",
      "-----train-----  epoch:16 loss:0.016 psnr:31.650\n",
      "-----eval-----  loss:0.017 psnr:31.569\n",
      "-----train-----  epoch:17 loss:0.014 psnr:31.844\n",
      "-----eval-----  loss:0.017 psnr:31.668\n",
      "-----train-----  epoch:18 loss:0.014 psnr:31.947\n",
      "-----eval-----  loss:0.015 psnr:31.805\n",
      "-----train-----  epoch:19 loss:0.013 psnr:32.031\n",
      "-----eval-----  loss:0.015 psnr:31.880\n",
      "-----train-----  epoch:20 loss:0.013 psnr:32.036\n",
      "-----eval-----  loss:0.016 psnr:31.771\n",
      "-----train-----  epoch:21 loss:0.012 psnr:32.183\n",
      "-----eval-----  loss:0.014 psnr:31.956\n",
      "-----train-----  epoch:22 loss:0.011 psnr:32.276\n",
      "-----eval-----  loss:0.014 psnr:32.030\n",
      "-----train-----  epoch:23 loss:0.011 psnr:32.348\n",
      "-----eval-----  loss:0.013 psnr:32.059\n",
      "-----train-----  epoch:24 loss:0.011 psnr:32.366\n",
      "-----eval-----  loss:0.013 psnr:32.170\n",
      "-----train-----  epoch:25 loss:0.010 psnr:32.431\n",
      "-----eval-----  loss:0.012 psnr:32.211\n",
      "-----train-----  epoch:26 loss:0.010 psnr:32.506\n",
      "-----eval-----  loss:0.012 psnr:32.271\n",
      "-----train-----  epoch:27 loss:0.010 psnr:32.570\n",
      "-----eval-----  loss:0.012 psnr:32.251\n",
      "-----train-----  epoch:28 loss:0.009 psnr:32.587\n",
      "-----eval-----  loss:0.012 psnr:32.332\n",
      "-----train-----  epoch:29 loss:0.009 psnr:32.622\n",
      "-----eval-----  loss:0.012 psnr:32.334\n",
      "-----train-----  epoch:0 loss:0.067 psnr:27.357\n",
      "-----eval-----  loss:0.056 psnr:27.895\n",
      "-----train-----  epoch:1 loss:0.056 psnr:28.184\n",
      "-----eval-----  loss:0.053 psnr:28.127\n",
      "-----train-----  epoch:2 loss:0.052 psnr:28.489\n",
      "-----eval-----  loss:0.054 psnr:28.333\n",
      "-----train-----  epoch:3 loss:0.045 psnr:28.988\n",
      "-----eval-----  loss:0.043 psnr:29.298\n",
      "-----train-----  epoch:4 loss:0.043 psnr:29.293\n",
      "-----eval-----  loss:0.047 psnr:29.109\n",
      "-----train-----  epoch:5 loss:0.040 psnr:29.618\n",
      "-----eval-----  loss:0.043 psnr:29.403\n",
      "-----train-----  epoch:6 loss:0.041 psnr:29.524\n",
      "-----eval-----  loss:0.052 psnr:28.919\n",
      "-----train-----  epoch:7 loss:0.039 psnr:29.686\n",
      "-----eval-----  loss:0.044 psnr:29.541\n",
      "-----train-----  epoch:8 loss:0.030 psnr:30.532\n",
      "-----eval-----  loss:0.032 psnr:30.555\n",
      "-----train-----  epoch:9 loss:0.028 psnr:30.914\n",
      "-----eval-----  loss:0.024 psnr:31.048\n",
      "-----train-----  epoch:10 loss:0.024 psnr:31.199\n",
      "-----eval-----  loss:0.028 psnr:30.910\n",
      "-----train-----  epoch:11 loss:0.021 psnr:31.506\n",
      "-----eval-----  loss:0.024 psnr:31.330\n",
      "-----train-----  epoch:12 loss:0.019 psnr:31.731\n",
      "-----eval-----  loss:0.019 psnr:31.817\n",
      "-----train-----  epoch:13 loss:0.018 psnr:31.876\n",
      "-----eval-----  loss:0.021 psnr:31.698\n",
      "-----train-----  epoch:14 loss:0.017 psnr:32.038\n",
      "-----eval-----  loss:0.019 psnr:31.859\n",
      "-----train-----  epoch:15 loss:0.016 psnr:32.203\n",
      "-----eval-----  loss:0.019 psnr:31.953\n",
      "-----train-----  epoch:16 loss:0.014 psnr:32.425\n",
      "-----eval-----  loss:0.016 psnr:32.158\n",
      "-----train-----  epoch:17 loss:0.013 psnr:32.579\n",
      "-----eval-----  loss:0.015 psnr:32.397\n",
      "-----train-----  epoch:18 loss:0.012 psnr:32.655\n",
      "-----eval-----  loss:0.015 psnr:32.409\n",
      "-----train-----  epoch:19 loss:0.011 psnr:32.767\n",
      "-----eval-----  loss:0.014 psnr:32.514\n",
      "-----train-----  epoch:20 loss:0.011 psnr:32.821\n",
      "-----eval-----  loss:0.012 psnr:32.680\n",
      "-----train-----  epoch:21 loss:0.011 psnr:32.936\n",
      "-----eval-----  loss:0.013 psnr:32.713\n",
      "-----train-----  epoch:22 loss:0.010 psnr:33.025\n",
      "-----eval-----  loss:0.012 psnr:32.682\n",
      "-----train-----  epoch:23 loss:0.010 psnr:33.055\n",
      "-----eval-----  loss:0.012 psnr:32.801\n",
      "-----train-----  epoch:24 loss:0.009 psnr:33.161\n",
      "-----eval-----  loss:0.011 psnr:32.928\n",
      "-----train-----  epoch:25 loss:0.009 psnr:33.241\n",
      "-----eval-----  loss:0.011 psnr:32.936\n",
      "-----train-----  epoch:26 loss:0.009 psnr:33.269\n",
      "-----eval-----  loss:0.011 psnr:33.011\n",
      "-----train-----  epoch:27 loss:0.008 psnr:33.325\n",
      "-----eval-----  loss:0.011 psnr:32.986\n",
      "-----train-----  epoch:28 loss:0.008 psnr:33.386\n",
      "-----eval-----  loss:0.011 psnr:32.998\n",
      "-----train-----  epoch:29 loss:0.008 psnr:33.410\n",
      "-----eval-----  loss:0.010 psnr:33.108\n",
      "-----eval-----  loss:0.010 psnr:33.108\n",
      "Training time: 274.43 s\n",
      "Rendering quality: 33.11 dB\n",
      "Rendering speed: 102.79 fps\n",
      "Model size: 7.38 MB\n"
     ]
    }
   ],
   "source": [
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname hotdog --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.012 --splatting_r 0.015 --use_msssim True --use_dists False --use_edges False \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548176a-82b2-42cb-b920-9171536c775a",
   "metadata": {},
   "source": [
    "# Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce7d16e4-9546-41e0-b3e9-29c194fbbb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  False\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.39it/s]\n",
      "Initialization, data:hotdog point:(1341362, 6)\n",
      "Initialized point number:16096\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/hotdog/v2_0.012_0.015/msssimFalsedistsFalseedgesTrue\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 loss:0.208 psnr:20.211\n",
      "-----eval-----  loss:0.203 psnr:21.592\n",
      "-----train-----  epoch:1 loss:0.193 psnr:22.723\n",
      "-----eval-----  loss:0.187 psnr:23.238\n",
      "-----train-----  epoch:2 loss:0.177 psnr:24.159\n",
      "-----eval-----  loss:0.173 psnr:24.301\n",
      "-----train-----  epoch:3 loss:0.164 psnr:25.053\n",
      "-----eval-----  loss:0.162 psnr:25.001\n",
      "-----train-----  epoch:4 loss:0.154 psnr:25.701\n",
      "-----eval-----  loss:0.153 psnr:25.527\n",
      "-----train-----  epoch:5 loss:0.146 psnr:26.189\n",
      "-----eval-----  loss:0.145 psnr:26.019\n",
      "-----train-----  epoch:6 loss:0.139 psnr:26.578\n",
      "-----eval-----  loss:0.140 psnr:26.366\n",
      "-----train-----  epoch:7 loss:0.134 psnr:26.895\n",
      "-----eval-----  loss:0.134 psnr:26.634\n",
      "-----train-----  epoch:8 loss:0.128 psnr:27.170\n",
      "-----eval-----  loss:0.130 psnr:26.886\n",
      "-----train-----  epoch:9 loss:0.124 psnr:27.372\n",
      "-----eval-----  loss:0.126 psnr:27.035\n",
      "-----train-----  epoch:10 loss:0.120 psnr:27.578\n",
      "-----eval-----  loss:0.124 psnr:27.206\n",
      "-----train-----  epoch:11 loss:0.117 psnr:27.723\n",
      "-----eval-----  loss:0.120 psnr:27.352\n",
      "-----train-----  epoch:12 loss:0.114 psnr:27.862\n",
      "-----eval-----  loss:0.118 psnr:27.444\n",
      "-----train-----  epoch:13 loss:0.112 psnr:27.989\n",
      "-----eval-----  loss:0.115 psnr:27.541\n",
      "-----train-----  epoch:14 loss:0.109 psnr:28.099\n",
      "-----eval-----  loss:0.113 psnr:27.697\n",
      "-----train-----  epoch:15 loss:0.107 psnr:28.218\n",
      "-----eval-----  loss:0.111 psnr:27.759\n",
      "-----train-----  epoch:16 loss:0.105 psnr:28.294\n",
      "-----eval-----  loss:0.110 psnr:27.838\n",
      "-----train-----  epoch:17 loss:0.104 psnr:28.406\n",
      "-----eval-----  loss:0.108 psnr:27.928\n",
      "-----train-----  epoch:18 loss:0.102 psnr:28.491\n",
      "-----eval-----  loss:0.107 psnr:27.991\n",
      "-----train-----  epoch:19 loss:0.101 psnr:28.574\n",
      "-----eval-----  loss:0.105 psnr:28.073\n",
      "-----train-----  epoch:0 loss:0.209 psnr:21.771\n",
      "-----eval-----  loss:0.184 psnr:24.729\n",
      "-----train-----  epoch:1 loss:0.157 psnr:25.830\n",
      "-----eval-----  loss:0.145 psnr:26.221\n",
      "-----train-----  epoch:2 loss:0.132 psnr:27.249\n",
      "-----eval-----  loss:0.131 psnr:27.618\n",
      "-----train-----  epoch:3 loss:0.118 psnr:28.206\n",
      "-----eval-----  loss:0.124 psnr:27.456\n",
      "-----train-----  epoch:4 loss:0.111 psnr:28.648\n",
      "-----eval-----  loss:0.113 psnr:28.474\n",
      "-----train-----  epoch:5 loss:0.102 psnr:29.215\n",
      "-----eval-----  loss:0.118 psnr:28.636\n",
      "-----train-----  epoch:6 loss:0.100 psnr:29.471\n",
      "-----eval-----  loss:0.102 psnr:29.224\n",
      "-----train-----  epoch:7 loss:0.093 psnr:29.898\n",
      "-----eval-----  loss:0.105 psnr:29.375\n",
      "-----train-----  epoch:8 loss:0.090 psnr:30.128\n",
      "-----eval-----  loss:0.096 psnr:29.761\n",
      "-----train-----  epoch:9 loss:0.084 psnr:30.506\n",
      "-----eval-----  loss:0.090 psnr:30.062\n",
      "-----train-----  epoch:10 loss:0.083 psnr:30.580\n",
      "-----eval-----  loss:0.088 psnr:30.008\n",
      "-----train-----  epoch:11 loss:0.080 psnr:30.740\n",
      "-----eval-----  loss:0.090 psnr:30.054\n",
      "-----train-----  epoch:12 loss:0.077 psnr:30.969\n",
      "-----eval-----  loss:0.084 psnr:30.365\n",
      "-----train-----  epoch:13 loss:0.075 psnr:31.109\n",
      "-----eval-----  loss:0.082 psnr:30.410\n",
      "-----train-----  epoch:14 loss:0.074 psnr:31.107\n",
      "-----eval-----  loss:0.080 psnr:30.633\n",
      "-----train-----  epoch:15 loss:0.072 psnr:31.246\n",
      "-----eval-----  loss:0.081 psnr:30.599\n",
      "-----train-----  epoch:16 loss:0.071 psnr:31.352\n",
      "-----eval-----  loss:0.079 psnr:30.682\n",
      "-----train-----  epoch:17 loss:0.070 psnr:31.489\n",
      "-----eval-----  loss:0.076 psnr:30.843\n",
      "-----train-----  epoch:18 loss:0.068 psnr:31.562\n",
      "-----eval-----  loss:0.076 psnr:30.858\n",
      "-----train-----  epoch:19 loss:0.067 psnr:31.667\n",
      "-----eval-----  loss:0.076 psnr:30.848\n",
      "-----train-----  epoch:20 loss:0.067 psnr:31.696\n",
      "-----eval-----  loss:0.074 psnr:30.899\n",
      "-----train-----  epoch:21 loss:0.066 psnr:31.755\n",
      "-----eval-----  loss:0.074 psnr:31.010\n",
      "-----train-----  epoch:22 loss:0.065 psnr:31.793\n",
      "-----eval-----  loss:0.074 psnr:30.991\n",
      "-----train-----  epoch:23 loss:0.064 psnr:31.887\n",
      "-----eval-----  loss:0.073 psnr:31.016\n",
      "-----train-----  epoch:24 loss:0.063 psnr:31.952\n",
      "-----eval-----  loss:0.072 psnr:31.120\n",
      "-----train-----  epoch:25 loss:0.063 psnr:31.946\n",
      "-----eval-----  loss:0.073 psnr:31.057\n",
      "-----train-----  epoch:26 loss:0.063 psnr:32.021\n",
      "-----eval-----  loss:0.072 psnr:31.079\n",
      "-----train-----  epoch:27 loss:0.062 psnr:32.045\n",
      "-----eval-----  loss:0.071 psnr:31.200\n",
      "-----train-----  epoch:28 loss:0.062 psnr:32.075\n",
      "-----eval-----  loss:0.070 psnr:31.213\n",
      "-----train-----  epoch:29 loss:0.061 psnr:32.118\n",
      "-----eval-----  loss:0.071 psnr:31.162\n",
      "-----train-----  epoch:0 loss:0.119 psnr:28.944\n",
      "-----eval-----  loss:0.107 psnr:29.637\n",
      "-----train-----  epoch:1 loss:0.087 psnr:30.682\n",
      "-----eval-----  loss:0.115 psnr:29.530\n",
      "-----train-----  epoch:2 loss:0.075 psnr:31.394\n",
      "-----eval-----  loss:0.076 psnr:31.246\n",
      "-----train-----  epoch:3 loss:0.071 psnr:31.568\n",
      "-----eval-----  loss:0.069 psnr:31.445\n",
      "-----train-----  epoch:4 loss:0.066 psnr:31.842\n",
      "-----eval-----  loss:0.066 psnr:31.444\n",
      "-----train-----  epoch:5 loss:0.073 psnr:31.567\n",
      "-----eval-----  loss:0.061 psnr:32.171\n",
      "-----train-----  epoch:6 loss:0.059 psnr:32.408\n",
      "-----eval-----  loss:0.056 psnr:32.409\n",
      "-----train-----  epoch:7 loss:0.056 psnr:32.684\n",
      "-----eval-----  loss:0.069 psnr:31.441\n",
      "-----train-----  epoch:8 loss:0.057 psnr:32.701\n",
      "-----eval-----  loss:0.063 psnr:31.898\n",
      "-----train-----  epoch:9 loss:0.056 psnr:32.889\n",
      "-----eval-----  loss:0.057 psnr:32.294\n",
      "-----train-----  epoch:10 loss:0.050 psnr:33.293\n",
      "-----eval-----  loss:0.051 psnr:32.952\n",
      "-----train-----  epoch:11 loss:0.047 psnr:33.579\n",
      "-----eval-----  loss:0.050 psnr:33.077\n",
      "-----train-----  epoch:12 loss:0.048 psnr:33.536\n",
      "-----eval-----  loss:0.055 psnr:32.579\n",
      "-----train-----  epoch:13 loss:0.047 psnr:33.619\n",
      "-----eval-----  loss:0.047 psnr:33.306\n",
      "-----train-----  epoch:14 loss:0.044 psnr:33.983\n",
      "-----eval-----  loss:0.047 psnr:33.371\n",
      "-----train-----  epoch:15 loss:0.043 psnr:34.087\n",
      "-----eval-----  loss:0.046 psnr:33.340\n",
      "-----train-----  epoch:16 loss:0.043 psnr:34.110\n",
      "-----eval-----  loss:0.045 psnr:33.562\n",
      "-----train-----  epoch:17 loss:0.042 psnr:34.261\n",
      "-----eval-----  loss:0.045 psnr:33.613\n",
      "-----train-----  epoch:18 loss:0.041 psnr:34.344\n",
      "-----eval-----  loss:0.045 psnr:33.673\n",
      "-----train-----  epoch:19 loss:0.041 psnr:34.374\n",
      "-----eval-----  loss:0.043 psnr:33.873\n",
      "-----train-----  epoch:20 loss:0.041 psnr:34.411\n",
      "-----eval-----  loss:0.045 psnr:33.525\n",
      "-----train-----  epoch:21 loss:0.040 psnr:34.575\n",
      "-----eval-----  loss:0.044 psnr:33.770\n",
      "-----train-----  epoch:22 loss:0.039 psnr:34.666\n",
      "-----eval-----  loss:0.044 psnr:33.776\n",
      "-----train-----  epoch:23 loss:0.039 psnr:34.688\n",
      "-----eval-----  loss:0.043 psnr:33.811\n",
      "-----train-----  epoch:24 loss:0.039 psnr:34.699\n",
      "-----eval-----  loss:0.042 psnr:33.973\n",
      "-----train-----  epoch:25 loss:0.038 psnr:34.823\n",
      "-----eval-----  loss:0.042 psnr:34.055\n",
      "-----train-----  epoch:26 loss:0.038 psnr:34.867\n",
      "-----eval-----  loss:0.042 psnr:34.066\n",
      "-----train-----  epoch:27 loss:0.038 psnr:34.916\n",
      "-----eval-----  loss:0.042 psnr:34.002\n",
      "-----train-----  epoch:28 loss:0.038 psnr:34.918\n",
      "-----eval-----  loss:0.041 psnr:34.130\n",
      "-----train-----  epoch:29 loss:0.037 psnr:34.957\n",
      "-----eval-----  loss:0.041 psnr:34.074\n",
      "-----train-----  epoch:0 loss:0.107 psnr:29.800\n",
      "-----eval-----  loss:0.093 psnr:30.132\n",
      "-----train-----  epoch:1 loss:0.088 psnr:30.649\n",
      "-----eval-----  loss:0.087 psnr:30.655\n",
      "-----train-----  epoch:2 loss:0.081 psnr:31.089\n",
      "-----eval-----  loss:0.085 psnr:30.488\n",
      "-----train-----  epoch:3 loss:0.073 psnr:31.518\n",
      "-----eval-----  loss:0.069 psnr:31.592\n",
      "-----train-----  epoch:4 loss:0.069 psnr:31.879\n",
      "-----eval-----  loss:0.073 psnr:31.440\n",
      "-----train-----  epoch:5 loss:0.063 psnr:32.278\n",
      "-----eval-----  loss:0.070 psnr:31.514\n",
      "-----train-----  epoch:6 loss:0.066 psnr:32.117\n",
      "-----eval-----  loss:0.078 psnr:31.429\n",
      "-----train-----  epoch:7 loss:0.065 psnr:32.220\n",
      "-----eval-----  loss:0.068 psnr:31.630\n",
      "-----train-----  epoch:8 loss:0.053 psnr:33.157\n",
      "-----eval-----  loss:0.055 psnr:32.671\n",
      "-----train-----  epoch:9 loss:0.049 psnr:33.523\n",
      "-----eval-----  loss:0.049 psnr:33.161\n",
      "-----train-----  epoch:10 loss:0.048 psnr:33.708\n",
      "-----eval-----  loss:0.049 psnr:33.060\n",
      "-----train-----  epoch:11 loss:0.045 psnr:34.032\n",
      "-----eval-----  loss:0.050 psnr:33.289\n",
      "-----train-----  epoch:12 loss:0.045 psnr:34.019\n",
      "-----eval-----  loss:0.045 psnr:33.729\n",
      "-----train-----  epoch:13 loss:0.044 psnr:34.242\n",
      "-----eval-----  loss:0.048 psnr:33.564\n",
      "-----train-----  epoch:14 loss:0.043 psnr:34.398\n",
      "-----eval-----  loss:0.045 psnr:33.704\n",
      "-----train-----  epoch:15 loss:0.042 psnr:34.515\n",
      "-----eval-----  loss:0.045 psnr:33.717\n",
      "-----train-----  epoch:16 loss:0.040 psnr:34.738\n",
      "-----eval-----  loss:0.043 psnr:33.835\n",
      "-----train-----  epoch:17 loss:0.039 psnr:34.871\n",
      "-----eval-----  loss:0.041 psnr:34.186\n",
      "-----train-----  epoch:18 loss:0.039 psnr:34.928\n",
      "-----eval-----  loss:0.043 psnr:34.111\n",
      "-----train-----  epoch:19 loss:0.039 psnr:34.953\n",
      "-----eval-----  loss:0.042 psnr:34.189\n",
      "-----train-----  epoch:20 loss:0.038 psnr:35.032\n",
      "-----eval-----  loss:0.040 psnr:34.396\n",
      "-----train-----  epoch:21 loss:0.038 psnr:35.161\n",
      "-----eval-----  loss:0.040 psnr:34.357\n",
      "-----train-----  epoch:22 loss:0.037 psnr:35.233\n",
      "-----eval-----  loss:0.042 psnr:34.174\n",
      "-----train-----  epoch:23 loss:0.037 psnr:35.249\n",
      "-----eval-----  loss:0.040 psnr:34.427\n",
      "-----train-----  epoch:24 loss:0.036 psnr:35.381\n",
      "-----eval-----  loss:0.040 psnr:34.510\n",
      "-----train-----  epoch:25 loss:0.036 psnr:35.459\n",
      "-----eval-----  loss:0.039 psnr:34.514\n",
      "-----train-----  epoch:26 loss:0.036 psnr:35.447\n",
      "-----eval-----  loss:0.039 psnr:34.604\n",
      "-----train-----  epoch:27 loss:0.035 psnr:35.541\n",
      "-----eval-----  loss:0.040 psnr:34.500\n",
      "-----train-----  epoch:28 loss:0.035 psnr:35.581\n",
      "-----eval-----  loss:0.040 psnr:34.507\n",
      "-----train-----  epoch:29 loss:0.035 psnr:35.620\n",
      "-----eval-----  loss:0.038 psnr:34.727\n",
      "-----eval-----  loss:0.038 psnr:34.727\n",
      "Training time: 920.46 s\n",
      "Rendering quality: 34.73 dB\n",
      "Rendering speed: 99.54 fps\n",
      "Model size: 7.33 MB\n"
     ]
    }
   ],
   "source": [
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname hotdog --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.012 --splatting_r 0.015 --use_msssim False --use_dists False --use_edges True \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a14e8-7375-4d0b-ac36-56efde3c10b8",
   "metadata": {},
   "source": [
    "# MS-SSIM & Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "881b3afa-970d-46d7-8d23-204f35cb0de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.40it/s]\n",
      "Initialization, data:hotdog point:(1341362, 6)\n",
      "Initialized point number:16096\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/hotdog/v2_0.012_0.015/msssimTruedistsFalseedgesTrue\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 loss:0.388 psnr:19.959\n",
      "-----eval-----  loss:0.338 psnr:21.096\n",
      "-----train-----  epoch:1 loss:0.306 psnr:21.973\n",
      "-----eval-----  loss:0.296 psnr:22.429\n",
      "-----train-----  epoch:2 loss:0.273 psnr:23.079\n",
      "-----eval-----  loss:0.272 psnr:23.267\n",
      "-----train-----  epoch:3 loss:0.253 psnr:23.787\n",
      "-----eval-----  loss:0.253 psnr:23.869\n",
      "-----train-----  epoch:4 loss:0.236 psnr:24.317\n",
      "-----eval-----  loss:0.239 psnr:24.296\n",
      "-----train-----  epoch:5 loss:0.223 psnr:24.735\n",
      "-----eval-----  loss:0.227 psnr:24.684\n",
      "-----train-----  epoch:6 loss:0.212 psnr:25.073\n",
      "-----eval-----  loss:0.216 psnr:24.968\n",
      "-----train-----  epoch:7 loss:0.204 psnr:25.323\n",
      "-----eval-----  loss:0.208 psnr:25.191\n",
      "-----train-----  epoch:8 loss:0.196 psnr:25.563\n",
      "-----eval-----  loss:0.201 psnr:25.412\n",
      "-----train-----  epoch:9 loss:0.190 psnr:25.757\n",
      "-----eval-----  loss:0.196 psnr:25.522\n",
      "-----train-----  epoch:10 loss:0.185 psnr:25.919\n",
      "-----eval-----  loss:0.192 psnr:25.677\n",
      "-----train-----  epoch:11 loss:0.180 psnr:26.060\n",
      "-----eval-----  loss:0.186 psnr:25.805\n",
      "-----train-----  epoch:12 loss:0.176 psnr:26.180\n",
      "-----eval-----  loss:0.183 psnr:25.900\n",
      "-----train-----  epoch:13 loss:0.172 psnr:26.299\n",
      "-----eval-----  loss:0.179 psnr:25.994\n",
      "-----train-----  epoch:14 loss:0.168 psnr:26.388\n",
      "-----eval-----  loss:0.175 psnr:26.104\n",
      "-----train-----  epoch:15 loss:0.165 psnr:26.496\n",
      "-----eval-----  loss:0.172 psnr:26.171\n",
      "-----train-----  epoch:16 loss:0.162 psnr:26.560\n",
      "-----eval-----  loss:0.171 psnr:26.219\n",
      "-----train-----  epoch:17 loss:0.160 psnr:26.648\n",
      "-----eval-----  loss:0.168 psnr:26.303\n",
      "-----train-----  epoch:18 loss:0.158 psnr:26.709\n",
      "-----eval-----  loss:0.166 psnr:26.346\n",
      "-----train-----  epoch:19 loss:0.155 psnr:26.780\n",
      "-----eval-----  loss:0.164 psnr:26.417\n",
      "-----train-----  epoch:0 loss:0.353 psnr:20.296\n",
      "-----eval-----  loss:0.302 psnr:22.395\n",
      "-----train-----  epoch:1 loss:0.276 psnr:22.994\n",
      "-----eval-----  loss:0.267 psnr:23.532\n",
      "-----train-----  epoch:2 loss:0.246 psnr:24.044\n",
      "-----eval-----  loss:0.249 psnr:24.284\n",
      "-----train-----  epoch:3 loss:0.229 psnr:24.707\n",
      "-----eval-----  loss:0.240 psnr:24.819\n",
      "-----train-----  epoch:4 loss:0.222 psnr:25.107\n",
      "-----eval-----  loss:0.219 psnr:25.263\n",
      "-----train-----  epoch:5 loss:0.208 psnr:25.534\n",
      "-----eval-----  loss:0.237 psnr:25.384\n",
      "-----train-----  epoch:6 loss:0.201 psnr:25.881\n",
      "-----eval-----  loss:0.201 psnr:25.960\n",
      "-----train-----  epoch:7 loss:0.185 psnr:26.279\n",
      "-----eval-----  loss:0.196 psnr:26.282\n",
      "-----train-----  epoch:8 loss:0.178 psnr:26.580\n",
      "-----eval-----  loss:0.195 psnr:26.405\n",
      "-----train-----  epoch:9 loss:0.166 psnr:26.886\n",
      "-----eval-----  loss:0.162 psnr:26.799\n",
      "-----train-----  epoch:10 loss:0.157 psnr:27.071\n",
      "-----eval-----  loss:0.161 psnr:26.943\n",
      "-----train-----  epoch:11 loss:0.148 psnr:27.275\n",
      "-----eval-----  loss:0.164 psnr:27.063\n",
      "-----train-----  epoch:12 loss:0.142 psnr:27.476\n",
      "-----eval-----  loss:0.148 psnr:27.303\n",
      "-----train-----  epoch:13 loss:0.132 psnr:27.687\n",
      "-----eval-----  loss:0.140 psnr:27.469\n",
      "-----train-----  epoch:14 loss:0.130 psnr:27.768\n",
      "-----eval-----  loss:0.140 psnr:27.594\n",
      "-----train-----  epoch:15 loss:0.128 psnr:27.872\n",
      "-----eval-----  loss:0.138 psnr:27.644\n",
      "-----train-----  epoch:16 loss:0.123 psnr:28.020\n",
      "-----eval-----  loss:0.133 psnr:27.768\n",
      "-----train-----  epoch:17 loss:0.119 psnr:28.145\n",
      "-----eval-----  loss:0.127 psnr:27.893\n",
      "-----train-----  epoch:18 loss:0.115 psnr:28.258\n",
      "-----eval-----  loss:0.129 psnr:27.958\n",
      "-----train-----  epoch:19 loss:0.113 psnr:28.342\n",
      "-----eval-----  loss:0.125 psnr:28.045\n",
      "-----train-----  epoch:20 loss:0.111 psnr:28.444\n",
      "-----eval-----  loss:0.122 psnr:28.130\n",
      "-----train-----  epoch:21 loss:0.109 psnr:28.514\n",
      "-----eval-----  loss:0.120 psnr:28.201\n",
      "-----train-----  epoch:22 loss:0.108 psnr:28.596\n",
      "-----eval-----  loss:0.120 psnr:28.275\n",
      "-----train-----  epoch:23 loss:0.106 psnr:28.666\n",
      "-----eval-----  loss:0.117 psnr:28.360\n",
      "-----train-----  epoch:24 loss:0.105 psnr:28.778\n",
      "-----eval-----  loss:0.117 psnr:28.389\n",
      "-----train-----  epoch:25 loss:0.104 psnr:28.798\n",
      "-----eval-----  loss:0.117 psnr:28.440\n",
      "-----train-----  epoch:26 loss:0.103 psnr:28.862\n",
      "-----eval-----  loss:0.115 psnr:28.503\n",
      "-----train-----  epoch:27 loss:0.102 psnr:28.934\n",
      "-----eval-----  loss:0.114 psnr:28.534\n",
      "-----train-----  epoch:28 loss:0.101 psnr:28.961\n",
      "-----eval-----  loss:0.114 psnr:28.584\n",
      "-----train-----  epoch:29 loss:0.100 psnr:29.001\n",
      "-----eval-----  loss:0.113 psnr:28.612\n",
      "-----train-----  epoch:0 loss:0.221 psnr:26.213\n",
      "-----eval-----  loss:0.224 psnr:26.671\n",
      "-----train-----  epoch:1 loss:0.185 psnr:27.498\n",
      "-----eval-----  loss:0.213 psnr:26.959\n",
      "-----train-----  epoch:2 loss:0.154 psnr:28.267\n",
      "-----eval-----  loss:0.161 psnr:28.212\n",
      "-----train-----  epoch:3 loss:0.150 psnr:28.522\n",
      "-----eval-----  loss:0.145 psnr:28.702\n",
      "-----train-----  epoch:4 loss:0.131 psnr:29.001\n",
      "-----eval-----  loss:0.130 psnr:29.098\n",
      "-----train-----  epoch:5 loss:0.143 psnr:28.860\n",
      "-----eval-----  loss:0.116 psnr:29.572\n",
      "-----train-----  epoch:6 loss:0.120 psnr:29.509\n",
      "-----eval-----  loss:0.105 psnr:29.915\n",
      "-----train-----  epoch:7 loss:0.109 psnr:29.863\n",
      "-----eval-----  loss:0.143 psnr:29.130\n",
      "-----train-----  epoch:8 loss:0.109 psnr:29.910\n",
      "-----eval-----  loss:0.116 psnr:29.730\n",
      "-----train-----  epoch:9 loss:0.104 psnr:30.147\n",
      "-----eval-----  loss:0.104 psnr:30.113\n",
      "-----train-----  epoch:10 loss:0.091 psnr:30.531\n",
      "-----eval-----  loss:0.087 psnr:30.705\n",
      "-----train-----  epoch:11 loss:0.080 psnr:30.938\n",
      "-----eval-----  loss:0.087 psnr:30.797\n",
      "-----train-----  epoch:12 loss:0.080 psnr:31.002\n",
      "-----eval-----  loss:0.095 psnr:30.616\n",
      "-----train-----  epoch:13 loss:0.077 psnr:31.097\n",
      "-----eval-----  loss:0.077 psnr:31.143\n",
      "-----train-----  epoch:14 loss:0.069 psnr:31.444\n",
      "-----eval-----  loss:0.073 psnr:31.369\n",
      "-----train-----  epoch:15 loss:0.067 psnr:31.610\n",
      "-----eval-----  loss:0.070 psnr:31.461\n",
      "-----train-----  epoch:16 loss:0.065 psnr:31.664\n",
      "-----eval-----  loss:0.069 psnr:31.568\n",
      "-----train-----  epoch:17 loss:0.062 psnr:31.853\n",
      "-----eval-----  loss:0.066 psnr:31.670\n",
      "-----train-----  epoch:18 loss:0.060 psnr:31.953\n",
      "-----eval-----  loss:0.064 psnr:31.798\n",
      "-----train-----  epoch:19 loss:0.058 psnr:32.040\n",
      "-----eval-----  loss:0.063 psnr:31.879\n",
      "-----train-----  epoch:20 loss:0.059 psnr:32.050\n",
      "-----eval-----  loss:0.066 psnr:31.757\n",
      "-----train-----  epoch:21 loss:0.056 psnr:32.194\n",
      "-----eval-----  loss:0.061 psnr:31.951\n",
      "-----train-----  epoch:22 loss:0.055 psnr:32.289\n",
      "-----eval-----  loss:0.061 psnr:32.017\n",
      "-----train-----  epoch:23 loss:0.054 psnr:32.360\n",
      "-----eval-----  loss:0.060 psnr:32.047\n",
      "-----train-----  epoch:24 loss:0.054 psnr:32.376\n",
      "-----eval-----  loss:0.059 psnr:32.161\n",
      "-----train-----  epoch:25 loss:0.053 psnr:32.443\n",
      "-----eval-----  loss:0.058 psnr:32.207\n",
      "-----train-----  epoch:26 loss:0.052 psnr:32.521\n",
      "-----eval-----  loss:0.057 psnr:32.269\n",
      "-----train-----  epoch:27 loss:0.051 psnr:32.585\n",
      "-----eval-----  loss:0.058 psnr:32.245\n",
      "-----train-----  epoch:28 loss:0.051 psnr:32.603\n",
      "-----eval-----  loss:0.057 psnr:32.327\n",
      "-----train-----  epoch:29 loss:0.051 psnr:32.638\n",
      "-----eval-----  loss:0.057 psnr:32.327\n",
      "-----train-----  epoch:0 loss:0.199 psnr:27.333\n",
      "-----eval-----  loss:0.178 psnr:27.809\n",
      "-----train-----  epoch:1 loss:0.171 psnr:28.154\n",
      "-----eval-----  loss:0.163 psnr:28.105\n",
      "-----train-----  epoch:2 loss:0.157 psnr:28.475\n",
      "-----eval-----  loss:0.166 psnr:28.350\n",
      "-----train-----  epoch:3 loss:0.140 psnr:28.989\n",
      "-----eval-----  loss:0.132 psnr:29.268\n",
      "-----train-----  epoch:4 loss:0.131 psnr:29.305\n",
      "-----eval-----  loss:0.145 psnr:29.080\n",
      "-----train-----  epoch:5 loss:0.125 psnr:29.610\n",
      "-----eval-----  loss:0.130 psnr:29.374\n",
      "-----train-----  epoch:6 loss:0.129 psnr:29.504\n",
      "-----eval-----  loss:0.156 psnr:28.882\n",
      "-----train-----  epoch:7 loss:0.122 psnr:29.727\n",
      "-----eval-----  loss:0.132 psnr:29.620\n",
      "-----train-----  epoch:8 loss:0.098 psnr:30.563\n",
      "-----eval-----  loss:0.100 psnr:30.534\n",
      "-----train-----  epoch:9 loss:0.090 psnr:30.910\n",
      "-----eval-----  loss:0.085 psnr:31.045\n",
      "-----train-----  epoch:10 loss:0.082 psnr:31.208\n",
      "-----eval-----  loss:0.089 psnr:30.902\n",
      "-----train-----  epoch:11 loss:0.075 psnr:31.517\n",
      "-----eval-----  loss:0.082 psnr:31.293\n",
      "-----train-----  epoch:12 loss:0.071 psnr:31.721\n",
      "-----eval-----  loss:0.069 psnr:31.786\n",
      "-----train-----  epoch:13 loss:0.068 psnr:31.873\n",
      "-----eval-----  loss:0.074 psnr:31.681\n",
      "-----train-----  epoch:14 loss:0.067 psnr:32.041\n",
      "-----eval-----  loss:0.070 psnr:31.847\n",
      "-----train-----  epoch:15 loss:0.063 psnr:32.207\n",
      "-----eval-----  loss:0.068 psnr:31.933\n",
      "-----train-----  epoch:16 loss:0.059 psnr:32.424\n",
      "-----eval-----  loss:0.064 psnr:32.125\n",
      "-----train-----  epoch:17 loss:0.056 psnr:32.570\n",
      "-----eval-----  loss:0.060 psnr:32.365\n",
      "-----train-----  epoch:18 loss:0.055 psnr:32.655\n",
      "-----eval-----  loss:0.060 psnr:32.373\n",
      "-----train-----  epoch:19 loss:0.053 psnr:32.774\n",
      "-----eval-----  loss:0.058 psnr:32.494\n",
      "-----train-----  epoch:20 loss:0.052 psnr:32.822\n",
      "-----eval-----  loss:0.055 psnr:32.657\n",
      "-----train-----  epoch:21 loss:0.051 psnr:32.938\n",
      "-----eval-----  loss:0.055 psnr:32.673\n",
      "-----train-----  epoch:22 loss:0.049 psnr:33.022\n",
      "-----eval-----  loss:0.055 psnr:32.655\n",
      "-----train-----  epoch:23 loss:0.050 psnr:33.054\n",
      "-----eval-----  loss:0.054 psnr:32.772\n",
      "-----train-----  epoch:24 loss:0.048 psnr:33.164\n",
      "-----eval-----  loss:0.053 psnr:32.896\n",
      "-----train-----  epoch:25 loss:0.047 psnr:33.242\n",
      "-----eval-----  loss:0.052 psnr:32.897\n",
      "-----train-----  epoch:26 loss:0.047 psnr:33.266\n",
      "-----eval-----  loss:0.052 psnr:32.979\n",
      "-----train-----  epoch:27 loss:0.046 psnr:33.326\n",
      "-----eval-----  loss:0.052 psnr:32.942\n",
      "-----train-----  epoch:28 loss:0.046 psnr:33.385\n",
      "-----eval-----  loss:0.052 psnr:32.961\n",
      "-----train-----  epoch:29 loss:0.046 psnr:33.410\n",
      "-----eval-----  loss:0.050 psnr:33.083\n",
      "-----eval-----  loss:0.050 psnr:33.083\n",
      "Training time: 899.83 s\n",
      "Rendering quality: 33.08 dB\n",
      "Rendering speed: 101.58 fps\n",
      "Model size: 7.38 MB\n"
     ]
    }
   ],
   "source": [
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname hotdog --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.012 --splatting_r 0.015 --use_msssim True --use_dists False --use_edges True \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a1ced-b93a-43d6-8c1a-8438d79e058c",
   "metadata": {},
   "source": [
    "# EXPERIMENTS (NeRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74aba759-a6b2-4081-93c8-36b1c794aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.39it/s]\n",
      "Initialization, data:hotdog point:(1341362, 6)\n",
      "imagegt shape:  torch.Size([400, 400, 400, 3])\n",
      "Using splatting_r:  0.015\n",
      "Using data_r:  0.012\n",
      "Initialized point number:16096\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/hotdog/v2_0.012_0.015/msssimTruedistsFalseedgesTrueadaptive_splattingrFalseadaptive_datarFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 posedge_loss:11742.670 negedge_loss:4414.310 psnr:19.959\n",
      "-----eval-----  edge_loss:16143.087 psnr:21.096\n",
      "-----train-----  epoch:1 posedge_loss:11593.020 negedge_loss:3799.420 psnr:21.973\n",
      "-----eval-----  edge_loss:15196.826 psnr:22.430\n",
      "-----train-----  epoch:2 posedge_loss:10946.660 negedge_loss:3529.160 psnr:23.076\n",
      "-----eval-----  edge_loss:14413.348 psnr:23.259\n",
      "-----train-----  epoch:3 posedge_loss:10373.310 negedge_loss:3372.520 psnr:23.774\n",
      "-----eval-----  edge_loss:13665.479 psnr:23.862\n",
      "-----train-----  epoch:4 posedge_loss:9802.920 negedge_loss:3262.440 psnr:24.300\n",
      "-----eval-----  edge_loss:13137.174 psnr:24.293\n",
      "-----train-----  epoch:5 posedge_loss:9343.810 negedge_loss:3176.320 psnr:24.716\n",
      "-----eval-----  edge_loss:12607.087 psnr:24.678\n",
      "-----train-----  epoch:6 posedge_loss:8926.210 negedge_loss:3109.350 psnr:25.047\n",
      "-----eval-----  edge_loss:12096.218 psnr:24.958\n",
      "-----train-----  epoch:7 posedge_loss:8552.319 negedge_loss:3073.280 psnr:25.309\n",
      "-----eval-----  edge_loss:11679.652 psnr:25.200\n",
      "-----train-----  epoch:8 posedge_loss:8193.189 negedge_loss:3007.380 psnr:25.559\n",
      "-----eval-----  edge_loss:11349.696 psnr:25.425\n",
      "-----train-----  epoch:9 posedge_loss:7922.850 negedge_loss:2975.580 psnr:25.758\n",
      "-----eval-----  edge_loss:11103.044 psnr:25.542\n",
      "-----train-----  epoch:10 posedge_loss:7658.400 negedge_loss:2940.360 psnr:25.922\n",
      "-----eval-----  edge_loss:10872.913 psnr:25.694\n",
      "-----train-----  epoch:11 posedge_loss:7481.070 negedge_loss:2918.700 psnr:26.055\n",
      "-----eval-----  edge_loss:10632.609 psnr:25.808\n",
      "-----train-----  epoch:12 posedge_loss:7283.350 negedge_loss:2892.260 psnr:26.165\n",
      "-----eval-----  edge_loss:10501.826 psnr:25.893\n",
      "-----train-----  epoch:13 posedge_loss:7141.840 negedge_loss:2874.360 psnr:26.273\n",
      "-----eval-----  edge_loss:10206.913 psnr:25.979\n",
      "-----train-----  epoch:14 posedge_loss:6964.410 negedge_loss:2846.750 psnr:26.355\n",
      "-----eval-----  edge_loss:10089.000 psnr:26.084\n",
      "-----train-----  epoch:15 posedge_loss:6815.920 negedge_loss:2829.160 psnr:26.461\n",
      "-----eval-----  edge_loss:9920.565 psnr:26.149\n",
      "-----train-----  epoch:16 posedge_loss:6672.650 negedge_loss:2809.560 psnr:26.530\n",
      "-----eval-----  edge_loss:9902.479 psnr:26.199\n",
      "-----train-----  epoch:17 posedge_loss:6563.620 negedge_loss:2794.220 psnr:26.626\n",
      "-----eval-----  edge_loss:9728.479 psnr:26.286\n",
      "-----train-----  epoch:18 posedge_loss:6456.740 negedge_loss:2770.780 psnr:26.697\n",
      "-----eval-----  edge_loss:9606.305 psnr:26.332\n",
      "-----train-----  epoch:19 posedge_loss:6358.180 negedge_loss:2756.610 psnr:26.771\n",
      "-----eval-----  edge_loss:9473.348 psnr:26.409\n",
      "-----train-----  epoch:0 posedge_loss:13081.100 negedge_loss:3222.600 psnr:20.276\n",
      "-----eval-----  edge_loss:15541.261 psnr:22.374\n",
      "-----train-----  epoch:1 posedge_loss:11430.450 negedge_loss:2890.380 psnr:22.969\n",
      "-----eval-----  edge_loss:14198.174 psnr:23.488\n",
      "-----train-----  epoch:2 posedge_loss:10424.950 negedge_loss:2785.450 psnr:24.011\n",
      "-----eval-----  edge_loss:13392.652 psnr:24.264\n",
      "-----train-----  epoch:3 posedge_loss:9743.510 negedge_loss:2700.240 psnr:24.667\n",
      "-----eval-----  edge_loss:13075.913 psnr:24.769\n",
      "-----train-----  epoch:4 posedge_loss:9503.050 negedge_loss:2674.700 psnr:25.043\n",
      "-----eval-----  edge_loss:12131.870 psnr:25.190\n",
      "-----train-----  epoch:5 posedge_loss:8975.420 negedge_loss:2604.110 psnr:25.457\n",
      "-----eval-----  edge_loss:13017.696 psnr:25.307\n",
      "-----train-----  epoch:6 posedge_loss:8607.140 negedge_loss:2587.090 psnr:25.790\n",
      "-----eval-----  edge_loss:11328.000 psnr:25.861\n",
      "-----train-----  epoch:7 posedge_loss:7905.820 negedge_loss:2540.020 psnr:26.169\n",
      "-----eval-----  edge_loss:10979.565 psnr:26.186\n",
      "-----train-----  epoch:8 posedge_loss:7555.810 negedge_loss:2501.130 psnr:26.485\n",
      "-----eval-----  edge_loss:11051.521 psnr:26.365\n",
      "-----train-----  epoch:9 posedge_loss:7039.710 negedge_loss:2470.900 psnr:26.848\n",
      "-----eval-----  edge_loss:9353.087 psnr:26.780\n",
      "-----train-----  epoch:10 posedge_loss:6574.590 negedge_loss:2443.750 psnr:27.045\n",
      "-----eval-----  edge_loss:9243.392 psnr:26.927\n",
      "-----train-----  epoch:11 posedge_loss:6170.150 negedge_loss:2426.750 psnr:27.253\n",
      "-----eval-----  edge_loss:9417.652 psnr:27.067\n",
      "-----train-----  epoch:12 posedge_loss:5840.020 negedge_loss:2398.110 psnr:27.456\n",
      "-----eval-----  edge_loss:8632.131 psnr:27.291\n",
      "-----train-----  epoch:13 posedge_loss:5421.390 negedge_loss:2365.150 psnr:27.665\n",
      "-----eval-----  edge_loss:8214.652 psnr:27.451\n",
      "-----train-----  epoch:14 posedge_loss:5303.460 negedge_loss:2371.450 psnr:27.743\n",
      "-----eval-----  edge_loss:8241.218 psnr:27.587\n",
      "-----train-----  epoch:15 posedge_loss:5211.690 negedge_loss:2348.590 psnr:27.849\n",
      "-----eval-----  edge_loss:7969.479 psnr:27.627\n",
      "-----train-----  epoch:16 posedge_loss:4960.640 negedge_loss:2336.350 psnr:27.995\n",
      "-----eval-----  edge_loss:7836.218 psnr:27.755\n",
      "-----train-----  epoch:17 posedge_loss:4850.020 negedge_loss:2322.050 psnr:28.116\n",
      "-----eval-----  edge_loss:7534.348 psnr:27.866\n",
      "-----train-----  epoch:18 posedge_loss:4646.150 negedge_loss:2304.860 psnr:28.231\n",
      "-----eval-----  edge_loss:7568.652 psnr:27.927\n",
      "-----train-----  epoch:19 posedge_loss:4554.210 negedge_loss:2286.620 psnr:28.304\n",
      "-----eval-----  edge_loss:7420.174 psnr:28.020\n",
      "-----train-----  epoch:20 posedge_loss:4443.850 negedge_loss:2286.640 psnr:28.409\n",
      "-----eval-----  edge_loss:7319.609 psnr:28.087\n",
      "-----train-----  epoch:21 posedge_loss:4406.670 negedge_loss:2271.030 psnr:28.464\n",
      "-----eval-----  edge_loss:7148.435 psnr:28.136\n",
      "-----train-----  epoch:22 posedge_loss:4314.370 negedge_loss:2266.760 psnr:28.534\n",
      "-----eval-----  edge_loss:7237.522 psnr:28.196\n",
      "-----train-----  epoch:23 posedge_loss:4269.750 negedge_loss:2261.100 psnr:28.598\n",
      "-----eval-----  edge_loss:7076.087 psnr:28.280\n",
      "-----train-----  epoch:24 posedge_loss:4226.240 negedge_loss:2246.700 psnr:28.708\n",
      "-----eval-----  edge_loss:7059.087 psnr:28.311\n",
      "-----train-----  epoch:25 posedge_loss:4171.380 negedge_loss:2244.480 psnr:28.728\n",
      "-----eval-----  edge_loss:7063.783 psnr:28.362\n",
      "-----train-----  epoch:26 posedge_loss:4124.080 negedge_loss:2238.380 psnr:28.788\n",
      "-----eval-----  edge_loss:6945.435 psnr:28.421\n",
      "-----train-----  epoch:27 posedge_loss:4078.060 negedge_loss:2225.200 psnr:28.859\n",
      "-----eval-----  edge_loss:6903.957 psnr:28.448\n",
      "-----train-----  epoch:28 posedge_loss:4069.240 negedge_loss:2227.170 psnr:28.887\n",
      "-----eval-----  edge_loss:6894.305 psnr:28.501\n",
      "-----train-----  epoch:29 posedge_loss:4011.440 negedge_loss:2216.750 psnr:28.925\n",
      "-----eval-----  edge_loss:6861.043 psnr:28.529\n",
      "-----train-----  epoch:0 posedge_loss:8998.780 negedge_loss:2723.760 psnr:26.207\n",
      "-----eval-----  edge_loss:11809.000 psnr:26.707\n",
      "-----train-----  epoch:1 posedge_loss:7476.090 negedge_loss:2448.790 psnr:27.493\n",
      "-----eval-----  edge_loss:11257.044 psnr:26.957\n",
      "-----train-----  epoch:2 posedge_loss:5997.160 negedge_loss:2338.340 psnr:28.227\n",
      "-----eval-----  edge_loss:8798.826 psnr:28.134\n",
      "-----train-----  epoch:3 posedge_loss:5898.600 negedge_loss:2282.690 psnr:28.473\n",
      "-----eval-----  edge_loss:8055.305 psnr:28.651\n",
      "-----train-----  epoch:4 posedge_loss:5060.760 negedge_loss:2242.670 psnr:28.956\n",
      "-----eval-----  edge_loss:7152.435 psnr:29.032\n",
      "-----train-----  epoch:5 posedge_loss:5669.850 negedge_loss:2263.610 psnr:28.817\n",
      "-----eval-----  edge_loss:6494.696 psnr:29.482\n",
      "-----train-----  epoch:6 posedge_loss:4462.720 negedge_loss:2153.530 psnr:29.460\n",
      "-----eval-----  edge_loss:5980.739 psnr:29.818\n",
      "-----train-----  epoch:7 posedge_loss:4016.660 negedge_loss:2107.270 psnr:29.797\n",
      "-----eval-----  edge_loss:7721.609 psnr:29.094\n",
      "-----train-----  epoch:8 posedge_loss:3985.550 negedge_loss:2085.310 psnr:29.860\n",
      "-----eval-----  edge_loss:6342.696 psnr:29.672\n",
      "-----train-----  epoch:9 posedge_loss:3781.030 negedge_loss:2052.990 psnr:30.076\n",
      "-----eval-----  edge_loss:5756.826 psnr:30.064\n",
      "-----train-----  epoch:10 posedge_loss:3127.560 negedge_loss:1998.580 psnr:30.487\n",
      "-----eval-----  edge_loss:4967.392 psnr:30.651\n",
      "-----train-----  epoch:11 posedge_loss:2700.620 negedge_loss:1936.470 psnr:30.891\n",
      "-----eval-----  edge_loss:4981.522 psnr:30.747\n",
      "-----train-----  epoch:12 posedge_loss:2695.840 negedge_loss:1932.290 psnr:30.950\n",
      "-----eval-----  edge_loss:5222.696 psnr:30.596\n",
      "-----train-----  epoch:13 posedge_loss:2583.130 negedge_loss:1915.680 psnr:31.065\n",
      "-----eval-----  edge_loss:4438.479 psnr:31.134\n",
      "-----train-----  epoch:14 posedge_loss:2278.810 negedge_loss:1851.350 psnr:31.425\n",
      "-----eval-----  edge_loss:4306.479 psnr:31.362\n",
      "-----train-----  epoch:15 posedge_loss:2178.370 negedge_loss:1825.040 psnr:31.598\n",
      "-----eval-----  edge_loss:4202.696 psnr:31.430\n",
      "-----train-----  epoch:16 posedge_loss:2133.560 negedge_loss:1816.120 psnr:31.649\n",
      "-----eval-----  edge_loss:4157.696 psnr:31.567\n",
      "-----train-----  epoch:17 posedge_loss:2009.360 negedge_loss:1794.760 psnr:31.852\n",
      "-----eval-----  edge_loss:3987.000 psnr:31.666\n",
      "-----train-----  epoch:18 posedge_loss:1927.290 negedge_loss:1770.490 psnr:31.947\n",
      "-----eval-----  edge_loss:3917.435 psnr:31.816\n",
      "-----train-----  epoch:19 posedge_loss:1906.040 negedge_loss:1751.680 psnr:32.036\n",
      "-----eval-----  edge_loss:3875.826 psnr:31.890\n",
      "-----train-----  epoch:20 posedge_loss:1910.970 negedge_loss:1753.600 psnr:32.043\n",
      "-----eval-----  edge_loss:3890.783 psnr:31.769\n",
      "-----train-----  epoch:21 posedge_loss:1801.350 negedge_loss:1720.030 psnr:32.189\n",
      "-----eval-----  edge_loss:3832.087 psnr:31.966\n",
      "-----train-----  epoch:22 posedge_loss:1778.980 negedge_loss:1707.640 psnr:32.288\n",
      "-----eval-----  edge_loss:3784.131 psnr:32.037\n",
      "-----train-----  epoch:23 posedge_loss:1758.610 negedge_loss:1707.240 psnr:32.359\n",
      "-----eval-----  edge_loss:3728.783 psnr:32.071\n",
      "-----train-----  epoch:24 posedge_loss:1755.670 negedge_loss:1698.900 psnr:32.378\n",
      "-----eval-----  edge_loss:3663.391 psnr:32.186\n",
      "-----train-----  epoch:25 posedge_loss:1714.790 negedge_loss:1680.680 psnr:32.439\n",
      "-----eval-----  edge_loss:3664.131 psnr:32.224\n",
      "-----train-----  epoch:26 posedge_loss:1679.440 negedge_loss:1664.850 psnr:32.519\n",
      "-----eval-----  edge_loss:3624.261 psnr:32.291\n",
      "-----train-----  epoch:27 posedge_loss:1682.580 negedge_loss:1657.960 psnr:32.583\n",
      "-----eval-----  edge_loss:3630.304 psnr:32.263\n",
      "-----train-----  epoch:28 posedge_loss:1679.090 negedge_loss:1662.170 psnr:32.599\n",
      "-----eval-----  edge_loss:3582.609 psnr:32.347\n",
      "-----train-----  epoch:29 posedge_loss:1658.630 negedge_loss:1649.730 psnr:32.633\n",
      "-----eval-----  edge_loss:3591.522 psnr:32.350\n",
      "-----train-----  epoch:0 posedge_loss:8010.180 negedge_loss:2525.670 psnr:27.361\n",
      "-----eval-----  edge_loss:9669.174 psnr:27.875\n",
      "-----train-----  epoch:1 posedge_loss:6779.860 negedge_loss:2352.380 psnr:28.150\n",
      "-----eval-----  edge_loss:8697.261 psnr:28.150\n",
      "-----train-----  epoch:2 posedge_loss:6133.800 negedge_loss:2305.630 psnr:28.452\n",
      "-----eval-----  edge_loss:9142.783 psnr:28.306\n",
      "-----train-----  epoch:3 posedge_loss:5402.280 negedge_loss:2223.210 psnr:28.982\n",
      "-----eval-----  edge_loss:7063.565 psnr:29.249\n",
      "-----train-----  epoch:4 posedge_loss:4953.780 negedge_loss:2162.620 psnr:29.289\n",
      "-----eval-----  edge_loss:7691.870 psnr:29.087\n",
      "-----train-----  epoch:5 posedge_loss:4609.220 negedge_loss:2112.770 psnr:29.612\n",
      "-----eval-----  edge_loss:6957.435 psnr:29.450\n",
      "-----train-----  epoch:6 posedge_loss:4862.740 negedge_loss:2143.650 psnr:29.498\n",
      "-----eval-----  edge_loss:8369.783 psnr:28.892\n",
      "-----train-----  epoch:7 posedge_loss:4528.550 negedge_loss:2109.130 psnr:29.708\n",
      "-----eval-----  edge_loss:7022.174 psnr:29.607\n",
      "-----train-----  epoch:8 posedge_loss:3475.000 negedge_loss:1969.280 psnr:30.556\n",
      "-----eval-----  edge_loss:5541.913 psnr:30.570\n",
      "-----train-----  epoch:9 posedge_loss:3131.310 negedge_loss:1898.080 psnr:30.930\n",
      "-----eval-----  edge_loss:4713.913 psnr:31.088\n",
      "-----train-----  epoch:10 posedge_loss:2786.400 negedge_loss:1851.360 psnr:31.225\n",
      "-----eval-----  edge_loss:4888.435 psnr:30.950\n",
      "-----train-----  epoch:11 posedge_loss:2497.550 negedge_loss:1800.320 psnr:31.531\n",
      "-----eval-----  edge_loss:4531.957 psnr:31.345\n",
      "-----train-----  epoch:12 posedge_loss:2346.750 negedge_loss:1774.810 psnr:31.740\n",
      "-----eval-----  edge_loss:4006.131 psnr:31.822\n",
      "-----train-----  epoch:13 posedge_loss:2259.630 negedge_loss:1739.850 psnr:31.885\n",
      "-----eval-----  edge_loss:4233.783 psnr:31.683\n",
      "-----train-----  epoch:14 posedge_loss:2202.780 negedge_loss:1715.380 psnr:32.039\n",
      "-----eval-----  edge_loss:4014.826 psnr:31.859\n",
      "-----train-----  epoch:15 posedge_loss:2034.800 negedge_loss:1688.700 psnr:32.212\n",
      "-----eval-----  edge_loss:3933.826 psnr:31.960\n",
      "-----train-----  epoch:16 posedge_loss:1888.480 negedge_loss:1652.950 psnr:32.442\n",
      "-----eval-----  edge_loss:3738.870 psnr:32.168\n",
      "-----train-----  epoch:17 posedge_loss:1813.300 negedge_loss:1607.400 psnr:32.589\n",
      "-----eval-----  edge_loss:3582.304 psnr:32.399\n",
      "-----train-----  epoch:18 posedge_loss:1747.850 negedge_loss:1602.270 psnr:32.668\n",
      "-----eval-----  edge_loss:3580.043 psnr:32.416\n",
      "-----train-----  epoch:19 posedge_loss:1718.740 negedge_loss:1589.980 psnr:32.790\n",
      "-----eval-----  edge_loss:3554.696 psnr:32.535\n",
      "-----train-----  epoch:20 posedge_loss:1703.730 negedge_loss:1579.170 psnr:32.844\n",
      "-----eval-----  edge_loss:3406.478 psnr:32.696\n",
      "-----train-----  epoch:21 posedge_loss:1625.810 negedge_loss:1558.010 psnr:32.950\n",
      "-----eval-----  edge_loss:3374.783 psnr:32.720\n",
      "-----train-----  epoch:22 posedge_loss:1606.180 negedge_loss:1542.950 psnr:33.041\n",
      "-----eval-----  edge_loss:3398.391 psnr:32.693\n",
      "-----train-----  epoch:23 posedge_loss:1605.380 negedge_loss:1533.390 psnr:33.069\n",
      "-----eval-----  edge_loss:3371.304 psnr:32.806\n",
      "-----train-----  epoch:24 posedge_loss:1577.850 negedge_loss:1516.950 psnr:33.177\n",
      "-----eval-----  edge_loss:3289.957 psnr:32.929\n",
      "-----train-----  epoch:25 posedge_loss:1555.980 negedge_loss:1501.800 psnr:33.255\n",
      "-----eval-----  edge_loss:3284.783 psnr:32.942\n",
      "-----train-----  epoch:26 posedge_loss:1546.730 negedge_loss:1496.950 psnr:33.280\n",
      "-----eval-----  edge_loss:3272.696 psnr:33.016\n",
      "-----train-----  epoch:27 posedge_loss:1527.540 negedge_loss:1482.850 psnr:33.338\n",
      "-----eval-----  edge_loss:3312.913 psnr:32.982\n",
      "-----train-----  epoch:28 posedge_loss:1521.200 negedge_loss:1473.930 psnr:33.397\n",
      "-----eval-----  edge_loss:3283.957 psnr:33.004\n",
      "-----train-----  epoch:29 posedge_loss:1503.750 negedge_loss:1467.680 psnr:33.426\n",
      "-----eval-----  edge_loss:3214.304 psnr:33.122\n",
      "-----eval-----  edge_loss:3214.348 psnr:33.122\n",
      "Training time: 950.84 s\n",
      "Rendering quality: 33.12 dB\n",
      "Rendering speed: 100.03 fps\n",
      "Model size: 7.37 MB\n"
     ]
    }
   ],
   "source": [
    "# HOTDOG\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname hotdog --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.012 --splatting_r 0.015 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62da5f79-a13f-424e-80f8-4c5a6b718572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cpu\n",
      "Are we using ms-ssim loss?  False\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  False\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "  4%|█▊                                        | 17/400 [01:00<22:34,  3.54s/it]^C\n",
      "  4%|█▊                                        | 17/400 [01:01<23:06,  3.62s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/network/by7705/cos526/point-radiance/main.py\", line 305, in <module>\n",
      "    args.memitem = dataset.genpc()\n",
      "  File \"/scratch/network/by7705/cos526/point-radiance/dataloader/dataset.py\", line 162, in genpc\n",
      "    uv = batch_get_uv_from_ray(H,W,K,poses,pts)\n",
      "  File \"/scratch/network/by7705/cos526/point-radiance/dataloader/dataset.py\", line 50, in batch_get_uv_from_ray\n",
      "    pts_local = torch.sum((pts[..., None, :] - poses[:, :3, -1])[..., None, :] * RT, -1)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# LEGO ORIGINAL\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname lego --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.08 --splatting_r 0.010 --use_msssim False --use_dists False --use_edges False --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb257241-bb03-4d73-9eae-2df84094bf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.40it/s]\n",
      "Initialization, data:lego point:(1316926, 6)\n",
      "imagegt shape:  torch.Size([400, 400, 400, 3])\n",
      "Using splatting_r:  0.01\n",
      "Using data_r:  0.08\n",
      "Initialized point number:105354\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/lego/v2_0.080_0.010/msssimTruedistsFalseedgesTrueadaptive_splattingrFalseadaptive_datarFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 posedge_loss:6127.530 negedge_loss:8548.840 psnr:20.939\n",
      "-----eval-----  edge_loss:14377.087 psnr:22.088\n",
      "-----train-----  epoch:1 posedge_loss:6656.140 negedge_loss:6745.090 psnr:22.869\n",
      "-----eval-----  edge_loss:13258.000 psnr:23.425\n",
      "-----train-----  epoch:2 posedge_loss:6445.240 negedge_loss:6051.210 psnr:23.940\n",
      "-----eval-----  edge_loss:12569.479 psnr:24.208\n",
      "-----train-----  epoch:3 posedge_loss:6176.970 negedge_loss:5643.600 psnr:24.646\n",
      "-----eval-----  edge_loss:11884.305 psnr:24.761\n",
      "-----train-----  epoch:4 posedge_loss:5951.820 negedge_loss:5353.380 psnr:25.179\n",
      "-----eval-----  edge_loss:11389.479 psnr:25.183\n",
      "-----train-----  epoch:5 posedge_loss:5678.610 negedge_loss:5115.260 psnr:25.605\n",
      "-----eval-----  edge_loss:11308.305 psnr:25.382\n",
      "-----train-----  epoch:6 posedge_loss:5563.520 negedge_loss:4997.900 psnr:25.867\n",
      "-----eval-----  edge_loss:10816.957 psnr:25.701\n",
      "-----train-----  epoch:7 posedge_loss:5392.270 negedge_loss:4865.730 psnr:26.099\n",
      "-----eval-----  edge_loss:10712.479 psnr:25.870\n",
      "-----train-----  epoch:8 posedge_loss:5261.990 negedge_loss:4763.640 psnr:26.310\n",
      "-----eval-----  edge_loss:10489.000 psnr:26.040\n",
      "-----train-----  epoch:9 posedge_loss:5148.940 negedge_loss:4698.110 psnr:26.469\n",
      "-----eval-----  edge_loss:10138.608 psnr:26.250\n",
      "-----train-----  epoch:10 posedge_loss:5022.590 negedge_loss:4574.100 psnr:26.654\n",
      "-----eval-----  edge_loss:9979.087 psnr:26.359\n",
      "-----train-----  epoch:11 posedge_loss:4952.160 negedge_loss:4516.460 psnr:26.761\n",
      "-----eval-----  edge_loss:9870.087 psnr:26.455\n",
      "-----train-----  epoch:12 posedge_loss:4853.820 negedge_loss:4482.880 psnr:26.852\n",
      "-----eval-----  edge_loss:9767.218 psnr:26.553\n",
      "-----train-----  epoch:13 posedge_loss:4800.320 negedge_loss:4409.370 psnr:26.963\n",
      "-----eval-----  edge_loss:9619.044 psnr:26.646\n",
      "-----train-----  epoch:14 posedge_loss:4750.260 negedge_loss:4378.170 psnr:27.026\n",
      "-----eval-----  edge_loss:9554.870 psnr:26.669\n",
      "-----train-----  epoch:15 posedge_loss:4644.300 negedge_loss:4313.040 psnr:27.133\n",
      "-----eval-----  edge_loss:9419.739 psnr:26.763\n",
      "-----train-----  epoch:16 posedge_loss:4622.950 negedge_loss:4271.530 psnr:27.196\n",
      "-----eval-----  edge_loss:9324.087 psnr:26.819\n",
      "-----train-----  epoch:17 posedge_loss:4541.660 negedge_loss:4232.950 psnr:27.277\n",
      "-----eval-----  edge_loss:9411.913 psnr:26.785\n",
      "-----train-----  epoch:18 posedge_loss:4522.980 negedge_loss:4210.800 psnr:27.320\n",
      "-----eval-----  edge_loss:9271.435 psnr:26.883\n",
      "-----train-----  epoch:19 posedge_loss:4497.330 negedge_loss:4190.810 psnr:27.351\n",
      "-----eval-----  edge_loss:9231.392 psnr:26.900\n",
      "-----train-----  epoch:0 posedge_loss:8579.420 negedge_loss:6022.660 psnr:19.829\n",
      "-----eval-----  edge_loss:13799.957 psnr:20.855\n",
      "-----train-----  epoch:1 posedge_loss:7515.160 negedge_loss:5612.390 psnr:21.624\n",
      "-----eval-----  edge_loss:13253.261 psnr:21.635\n",
      "-----train-----  epoch:2 posedge_loss:7108.100 negedge_loss:5457.520 psnr:22.313\n",
      "-----eval-----  edge_loss:12632.044 psnr:22.318\n",
      "-----train-----  epoch:3 posedge_loss:6773.720 negedge_loss:5287.030 psnr:22.896\n",
      "-----eval-----  edge_loss:12781.826 psnr:22.440\n",
      "-----train-----  epoch:4 posedge_loss:6621.200 negedge_loss:5211.110 psnr:23.210\n",
      "-----eval-----  edge_loss:11713.044 psnr:23.229\n",
      "-----train-----  epoch:5 posedge_loss:6196.600 negedge_loss:4991.260 psnr:23.777\n",
      "-----eval-----  edge_loss:11500.305 psnr:23.603\n",
      "-----train-----  epoch:6 posedge_loss:5971.160 negedge_loss:4825.070 psnr:24.184\n",
      "-----eval-----  edge_loss:11278.435 psnr:23.810\n",
      "-----train-----  epoch:7 posedge_loss:5712.250 negedge_loss:4678.540 psnr:24.568\n",
      "-----eval-----  edge_loss:10761.826 psnr:24.170\n",
      "-----train-----  epoch:8 posedge_loss:5507.570 negedge_loss:4522.990 psnr:24.899\n",
      "-----eval-----  edge_loss:10356.826 psnr:24.548\n",
      "-----train-----  epoch:9 posedge_loss:5389.310 negedge_loss:4453.720 psnr:25.129\n",
      "-----eval-----  edge_loss:10143.739 psnr:24.745\n",
      "-----train-----  epoch:10 posedge_loss:5153.790 negedge_loss:4296.130 psnr:25.449\n",
      "-----eval-----  edge_loss:10307.261 psnr:24.825\n",
      "-----train-----  epoch:11 posedge_loss:4977.560 negedge_loss:4184.800 psnr:25.733\n",
      "-----eval-----  edge_loss:9829.521 psnr:25.134\n",
      "-----train-----  epoch:12 posedge_loss:4862.590 negedge_loss:4075.310 psnr:25.960\n",
      "-----eval-----  edge_loss:9656.870 psnr:25.269\n",
      "-----train-----  epoch:13 posedge_loss:4681.150 negedge_loss:3984.530 psnr:26.163\n",
      "-----eval-----  edge_loss:9404.783 psnr:25.478\n",
      "-----train-----  epoch:14 posedge_loss:4536.340 negedge_loss:3901.560 psnr:26.392\n",
      "-----eval-----  edge_loss:9300.305 psnr:25.664\n",
      "-----train-----  epoch:15 posedge_loss:4443.850 negedge_loss:3811.970 psnr:26.587\n",
      "-----eval-----  edge_loss:9104.305 psnr:25.839\n",
      "-----train-----  epoch:16 posedge_loss:4390.390 negedge_loss:3768.430 psnr:26.725\n",
      "-----eval-----  edge_loss:9093.565 psnr:25.910\n",
      "-----train-----  epoch:17 posedge_loss:4236.500 negedge_loss:3668.790 psnr:26.937\n",
      "-----eval-----  edge_loss:8761.913 psnr:26.131\n",
      "-----train-----  epoch:18 posedge_loss:4106.050 negedge_loss:3585.790 psnr:27.107\n",
      "-----eval-----  edge_loss:8606.392 psnr:26.229\n",
      "-----train-----  epoch:19 posedge_loss:4015.960 negedge_loss:3538.210 psnr:27.239\n",
      "-----eval-----  edge_loss:8546.652 psnr:26.324\n",
      "-----train-----  epoch:20 posedge_loss:3978.490 negedge_loss:3499.910 psnr:27.331\n",
      "-----eval-----  edge_loss:8512.435 psnr:26.414\n",
      "-----train-----  epoch:21 posedge_loss:3887.790 negedge_loss:3437.510 psnr:27.478\n",
      "-----eval-----  edge_loss:8386.000 psnr:26.507\n",
      "-----train-----  epoch:22 posedge_loss:3875.100 negedge_loss:3429.170 psnr:27.518\n",
      "-----eval-----  edge_loss:8328.044 psnr:26.592\n",
      "-----train-----  epoch:23 posedge_loss:3786.520 negedge_loss:3362.570 psnr:27.652\n",
      "-----eval-----  edge_loss:8234.652 psnr:26.646\n",
      "-----train-----  epoch:24 posedge_loss:3755.190 negedge_loss:3330.720 psnr:27.731\n",
      "-----eval-----  edge_loss:8250.044 psnr:26.698\n",
      "-----train-----  epoch:25 posedge_loss:3722.170 negedge_loss:3286.380 psnr:27.822\n",
      "-----eval-----  edge_loss:8206.218 psnr:26.699\n",
      "-----train-----  epoch:26 posedge_loss:3656.730 negedge_loss:3265.040 psnr:27.878\n",
      "-----eval-----  edge_loss:8130.783 psnr:26.808\n",
      "-----train-----  epoch:27 posedge_loss:3627.500 negedge_loss:3224.600 psnr:27.968\n",
      "-----eval-----  edge_loss:8046.913 psnr:26.864\n",
      "-----train-----  epoch:28 posedge_loss:3610.190 negedge_loss:3214.870 psnr:28.008\n",
      "-----eval-----  edge_loss:8082.652 psnr:26.872\n",
      "-----train-----  epoch:29 posedge_loss:3580.920 negedge_loss:3192.190 psnr:28.072\n",
      "-----eval-----  edge_loss:8040.348 psnr:26.916\n",
      "-----train-----  epoch:0 posedge_loss:7061.960 negedge_loss:5332.360 psnr:23.665\n",
      "-----eval-----  edge_loss:12090.739 psnr:23.680\n",
      "-----train-----  epoch:1 posedge_loss:6477.410 negedge_loss:5157.420 psnr:24.013\n",
      "-----eval-----  edge_loss:11674.479 psnr:23.873\n",
      "-----train-----  epoch:2 posedge_loss:6265.320 negedge_loss:5015.210 psnr:24.295\n",
      "-----eval-----  edge_loss:12067.696 psnr:23.597\n",
      "-----train-----  epoch:3 posedge_loss:6204.370 negedge_loss:4982.290 psnr:24.339\n",
      "-----eval-----  edge_loss:11282.565 psnr:24.188\n",
      "-----train-----  epoch:4 posedge_loss:5843.570 negedge_loss:4764.620 psnr:24.836\n",
      "-----eval-----  edge_loss:10643.000 psnr:24.674\n",
      "-----train-----  epoch:5 posedge_loss:5500.750 negedge_loss:4558.070 psnr:25.251\n",
      "-----eval-----  edge_loss:10492.783 psnr:24.942\n",
      "-----train-----  epoch:6 posedge_loss:5357.630 negedge_loss:4424.500 psnr:25.558\n",
      "-----eval-----  edge_loss:10011.565 psnr:25.308\n",
      "-----train-----  epoch:7 posedge_loss:5005.520 negedge_loss:4205.490 psnr:26.031\n",
      "-----eval-----  edge_loss:9621.218 psnr:25.549\n",
      "-----train-----  epoch:8 posedge_loss:4999.920 negedge_loss:4170.170 psnr:26.135\n",
      "-----eval-----  edge_loss:9325.218 psnr:25.798\n",
      "-----train-----  epoch:9 posedge_loss:4627.310 negedge_loss:3955.470 psnr:26.602\n",
      "-----eval-----  edge_loss:8875.435 psnr:26.166\n",
      "-----train-----  epoch:10 posedge_loss:4448.670 negedge_loss:3833.870 psnr:26.883\n",
      "-----eval-----  edge_loss:9067.913 psnr:26.185\n",
      "-----train-----  epoch:11 posedge_loss:4310.740 negedge_loss:3738.880 psnr:27.121\n",
      "-----eval-----  edge_loss:8489.739 psnr:26.581\n",
      "-----train-----  epoch:12 posedge_loss:4129.000 negedge_loss:3608.800 psnr:27.418\n",
      "-----eval-----  edge_loss:7962.392 psnr:26.913\n",
      "-----train-----  epoch:13 posedge_loss:3938.130 negedge_loss:3501.330 psnr:27.666\n",
      "-----eval-----  edge_loss:7853.565 psnr:27.058\n",
      "-----train-----  epoch:14 posedge_loss:3877.330 negedge_loss:3424.940 psnr:27.851\n",
      "-----eval-----  edge_loss:8030.392 psnr:27.135\n",
      "-----train-----  epoch:15 posedge_loss:3769.310 negedge_loss:3347.620 psnr:28.037\n",
      "-----eval-----  edge_loss:7661.870 psnr:27.288\n",
      "-----train-----  epoch:16 posedge_loss:3645.150 negedge_loss:3265.030 psnr:28.225\n",
      "-----eval-----  edge_loss:7347.435 psnr:27.506\n",
      "-----train-----  epoch:17 posedge_loss:3516.000 negedge_loss:3172.860 psnr:28.432\n",
      "-----eval-----  edge_loss:7338.913 psnr:27.562\n",
      "-----train-----  epoch:18 posedge_loss:3467.250 negedge_loss:3137.670 psnr:28.527\n",
      "-----eval-----  edge_loss:7226.261 psnr:27.694\n",
      "-----train-----  epoch:19 posedge_loss:3362.010 negedge_loss:3064.210 psnr:28.691\n",
      "-----eval-----  edge_loss:7153.392 psnr:27.768\n",
      "-----train-----  epoch:20 posedge_loss:3285.200 negedge_loss:3015.550 psnr:28.834\n",
      "-----eval-----  edge_loss:6884.609 psnr:27.940\n",
      "-----train-----  epoch:21 posedge_loss:3216.240 negedge_loss:2960.440 psnr:28.939\n",
      "-----eval-----  edge_loss:6937.305 psnr:27.982\n",
      "-----train-----  epoch:22 posedge_loss:3165.120 negedge_loss:2913.150 psnr:29.070\n",
      "-----eval-----  edge_loss:6913.783 psnr:28.004\n",
      "-----train-----  epoch:23 posedge_loss:3102.640 negedge_loss:2863.150 psnr:29.160\n",
      "-----eval-----  edge_loss:6850.479 psnr:28.083\n",
      "-----train-----  epoch:24 posedge_loss:3058.900 negedge_loss:2833.610 psnr:29.264\n",
      "-----eval-----  edge_loss:6601.522 psnr:28.171\n",
      "-----train-----  epoch:25 posedge_loss:2989.450 negedge_loss:2790.870 psnr:29.366\n",
      "-----eval-----  edge_loss:6629.087 psnr:28.245\n",
      "-----train-----  epoch:26 posedge_loss:2977.070 negedge_loss:2765.350 psnr:29.416\n",
      "-----eval-----  edge_loss:6573.261 psnr:28.304\n",
      "-----train-----  epoch:27 posedge_loss:2918.090 negedge_loss:2729.520 psnr:29.500\n",
      "-----eval-----  edge_loss:6532.696 psnr:28.357\n",
      "-----train-----  epoch:28 posedge_loss:2905.770 negedge_loss:2706.090 psnr:29.564\n",
      "-----eval-----  edge_loss:6413.696 psnr:28.411\n",
      "-----train-----  epoch:29 posedge_loss:2842.750 negedge_loss:2680.200 psnr:29.641\n",
      "-----eval-----  edge_loss:6471.696 psnr:28.384\n",
      "-----train-----  epoch:0 posedge_loss:6996.220 negedge_loss:5171.440 psnr:23.957\n",
      "-----eval-----  edge_loss:12348.826 psnr:23.554\n",
      "-----train-----  epoch:1 posedge_loss:6527.820 negedge_loss:5068.710 psnr:24.140\n",
      "-----eval-----  edge_loss:12181.783 psnr:23.594\n",
      "-----train-----  epoch:2 posedge_loss:6292.310 negedge_loss:4964.240 psnr:24.340\n",
      "-----eval-----  edge_loss:10819.957 psnr:24.373\n",
      "-----train-----  epoch:3 posedge_loss:6133.890 negedge_loss:4874.860 psnr:24.591\n",
      "-----eval-----  edge_loss:11299.392 psnr:24.283\n",
      "-----train-----  epoch:4 posedge_loss:5896.800 negedge_loss:4703.310 psnr:24.914\n",
      "-----eval-----  edge_loss:10613.609 psnr:24.860\n",
      "-----train-----  epoch:5 posedge_loss:5565.930 negedge_loss:4512.510 psnr:25.367\n",
      "-----eval-----  edge_loss:10235.913 psnr:25.082\n",
      "-----train-----  epoch:6 posedge_loss:5254.280 negedge_loss:4316.110 psnr:25.782\n",
      "-----eval-----  edge_loss:9881.435 psnr:25.277\n",
      "-----train-----  epoch:7 posedge_loss:5133.310 negedge_loss:4211.950 psnr:26.033\n",
      "-----eval-----  edge_loss:10228.479 psnr:25.283\n",
      "-----train-----  epoch:8 posedge_loss:5002.430 negedge_loss:4127.040 psnr:26.262\n",
      "-----eval-----  edge_loss:9116.696 psnr:26.077\n",
      "-----train-----  epoch:9 posedge_loss:4676.810 negedge_loss:3914.350 psnr:26.733\n",
      "-----eval-----  edge_loss:8893.435 psnr:26.293\n",
      "-----train-----  epoch:10 posedge_loss:4438.930 negedge_loss:3789.100 psnr:27.048\n",
      "-----eval-----  edge_loss:8705.218 psnr:26.498\n",
      "-----train-----  epoch:11 posedge_loss:4281.160 negedge_loss:3656.030 psnr:27.338\n",
      "-----eval-----  edge_loss:8770.131 psnr:26.604\n",
      "-----train-----  epoch:12 posedge_loss:4117.710 negedge_loss:3529.090 psnr:27.641\n",
      "-----eval-----  edge_loss:7885.043 psnr:27.118\n",
      "-----train-----  epoch:13 posedge_loss:3920.270 negedge_loss:3422.210 psnr:27.937\n",
      "-----eval-----  edge_loss:7516.783 psnr:27.394\n",
      "-----train-----  epoch:14 posedge_loss:3799.090 negedge_loss:3342.200 psnr:28.116\n",
      "-----eval-----  edge_loss:7613.348 psnr:27.464\n",
      "-----train-----  epoch:15 posedge_loss:3623.530 negedge_loss:3234.510 psnr:28.382\n",
      "-----eval-----  edge_loss:7288.043 psnr:27.692\n",
      "-----train-----  epoch:16 posedge_loss:3576.650 negedge_loss:3181.140 psnr:28.540\n",
      "-----eval-----  edge_loss:7358.174 psnr:27.755\n",
      "-----train-----  epoch:17 posedge_loss:3529.890 negedge_loss:3131.860 psnr:28.667\n",
      "-----eval-----  edge_loss:7291.652 psnr:27.866\n",
      "-----train-----  epoch:18 posedge_loss:3367.140 negedge_loss:3029.350 psnr:28.904\n",
      "-----eval-----  edge_loss:6858.174 psnr:28.095\n",
      "-----train-----  epoch:19 posedge_loss:3255.680 negedge_loss:2959.420 psnr:29.076\n",
      "-----eval-----  edge_loss:6746.522 psnr:28.200\n",
      "-----train-----  epoch:20 posedge_loss:3166.250 negedge_loss:2890.950 psnr:29.250\n",
      "-----eval-----  edge_loss:6558.261 psnr:28.318\n",
      "-----train-----  epoch:21 posedge_loss:3152.720 negedge_loss:2886.090 psnr:29.310\n",
      "-----eval-----  edge_loss:6780.696 psnr:28.255\n",
      "-----train-----  epoch:22 posedge_loss:3100.010 negedge_loss:2839.100 psnr:29.418\n",
      "-----eval-----  edge_loss:6600.174 psnr:28.422\n",
      "-----train-----  epoch:23 posedge_loss:3002.950 negedge_loss:2780.480 psnr:29.572\n",
      "-----eval-----  edge_loss:6354.826 psnr:28.578\n",
      "-----train-----  epoch:24 posedge_loss:2951.540 negedge_loss:2734.840 psnr:29.674\n",
      "-----eval-----  edge_loss:6388.043 psnr:28.627\n",
      "-----train-----  epoch:25 posedge_loss:2931.290 negedge_loss:2699.150 psnr:29.768\n",
      "-----eval-----  edge_loss:6298.565 psnr:28.637\n",
      "-----train-----  epoch:26 posedge_loss:2881.850 negedge_loss:2668.860 psnr:29.847\n",
      "-----eval-----  edge_loss:6309.087 psnr:28.684\n",
      "-----train-----  epoch:27 posedge_loss:2831.810 negedge_loss:2645.280 psnr:29.932\n",
      "-----eval-----  edge_loss:6173.870 psnr:28.788\n",
      "-----train-----  epoch:28 posedge_loss:2798.800 negedge_loss:2600.120 psnr:30.013\n",
      "-----eval-----  edge_loss:6189.565 psnr:28.786\n",
      "-----train-----  epoch:29 posedge_loss:2749.740 negedge_loss:2575.650 psnr:30.088\n",
      "-----eval-----  edge_loss:6071.305 psnr:28.865\n",
      "-----eval-----  edge_loss:6071.479 psnr:28.865\n",
      "Training time: 769.50 s\n",
      "Rendering quality: 28.87 dB\n",
      "Rendering speed: 29.63 fps\n",
      "Model size: 36.87 MB\n"
     ]
    }
   ],
   "source": [
    "# LEGO NEW\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname lego --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.08 --splatting_r 0.010 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f638f-242f-4cd2-83d2-82172ea83f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATERIALS original\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname materials --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.03 --splatting_r 0.010 --use_msssim False --use_dists False --use_edges False --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92416f07-e526-4d9e-b975-186e552b0e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.43it/s]\n",
      "Initialization, data:materials point:(562321, 6)\n",
      "imagegt shape:  torch.Size([400, 400, 400, 3])\n",
      "Using splatting_r:  0.01\n",
      "Using data_r:  0.03\n",
      "Initialized point number:16869\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/materials/v2_0.030_0.010/msssimTruedistsFalseedgesTrueadaptive_splattingrFalseadaptive_datarFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 posedge_loss:8989.810 negedge_loss:5252.250 psnr:21.473\n",
      "-----eval-----  edge_loss:14445.479 psnr:21.850\n",
      "-----train-----  epoch:1 posedge_loss:9656.500 negedge_loss:4815.190 psnr:22.206\n",
      "-----eval-----  edge_loss:14501.826 psnr:22.073\n",
      "-----train-----  epoch:2 posedge_loss:9693.479 negedge_loss:4681.160 psnr:22.393\n",
      "-----eval-----  edge_loss:14452.870 psnr:22.138\n",
      "-----train-----  epoch:3 posedge_loss:9644.960 negedge_loss:4591.110 psnr:22.502\n",
      "-----eval-----  edge_loss:14295.392 psnr:22.203\n",
      "-----train-----  epoch:4 posedge_loss:9548.300 negedge_loss:4545.420 psnr:22.586\n",
      "-----eval-----  edge_loss:14269.305 psnr:22.181\n",
      "-----train-----  epoch:5 posedge_loss:9493.200 negedge_loss:4511.990 psnr:22.635\n",
      "-----eval-----  edge_loss:14187.739 psnr:22.201\n",
      "-----train-----  epoch:6 posedge_loss:9392.500 negedge_loss:4472.890 psnr:22.683\n",
      "-----eval-----  edge_loss:14162.739 psnr:22.195\n",
      "-----train-----  epoch:7 posedge_loss:9383.069 negedge_loss:4437.020 psnr:22.723\n",
      "-----eval-----  edge_loss:14101.609 psnr:22.179\n",
      "-----train-----  epoch:8 posedge_loss:9316.270 negedge_loss:4411.700 psnr:22.771\n",
      "-----eval-----  edge_loss:14088.870 psnr:22.218\n",
      "-----train-----  epoch:9 posedge_loss:9298.930 negedge_loss:4399.740 psnr:22.771\n",
      "-----eval-----  edge_loss:14047.392 psnr:22.209\n",
      "-----train-----  epoch:10 posedge_loss:9239.700 negedge_loss:4366.510 psnr:22.826\n",
      "-----eval-----  edge_loss:14008.305 psnr:22.218\n",
      "-----train-----  epoch:11 posedge_loss:9185.140 negedge_loss:4355.860 psnr:22.854\n",
      "-----eval-----  edge_loss:13971.261 psnr:22.220\n",
      "-----train-----  epoch:12 posedge_loss:9151.750 negedge_loss:4332.750 psnr:22.882\n",
      "-----eval-----  edge_loss:13974.174 psnr:22.231\n",
      "-----train-----  epoch:13 posedge_loss:9109.300 negedge_loss:4331.500 psnr:22.908\n",
      "-----eval-----  edge_loss:13973.000 psnr:22.212\n",
      "-----train-----  epoch:14 posedge_loss:9115.640 negedge_loss:4318.890 psnr:22.912\n",
      "-----eval-----  edge_loss:13919.696 psnr:22.246\n",
      "-----train-----  epoch:15 posedge_loss:9055.880 negedge_loss:4311.230 psnr:22.950\n",
      "-----eval-----  edge_loss:13937.870 psnr:22.233\n",
      "-----train-----  epoch:16 posedge_loss:9058.700 negedge_loss:4298.530 psnr:22.952\n",
      "-----eval-----  edge_loss:13944.565 psnr:22.212\n",
      "-----train-----  epoch:17 posedge_loss:9020.569 negedge_loss:4292.590 psnr:22.970\n",
      "-----eval-----  edge_loss:13930.522 psnr:22.233\n",
      "-----train-----  epoch:18 posedge_loss:9013.120 negedge_loss:4280.080 psnr:22.983\n",
      "-----eval-----  edge_loss:13905.000 psnr:22.232\n",
      "-----train-----  epoch:19 posedge_loss:8983.890 negedge_loss:4282.770 psnr:23.006\n",
      "-----eval-----  edge_loss:13930.870 psnr:22.225\n",
      "-----train-----  epoch:0 posedge_loss:9704.779 negedge_loss:4952.930 psnr:17.617\n",
      "-----eval-----  edge_loss:14122.652 psnr:18.935\n",
      "-----train-----  epoch:1 posedge_loss:9532.010 negedge_loss:4727.010 psnr:19.496\n",
      "-----eval-----  edge_loss:14120.609 psnr:20.024\n",
      "-----train-----  epoch:2 posedge_loss:9468.790 negedge_loss:4543.200 psnr:20.658\n",
      "-----eval-----  edge_loss:13905.696 psnr:20.763\n",
      "-----train-----  epoch:3 posedge_loss:9350.520 negedge_loss:4404.870 psnr:21.533\n",
      "-----eval-----  edge_loss:13841.783 psnr:21.317\n",
      "-----train-----  epoch:4 posedge_loss:9241.350 negedge_loss:4312.840 psnr:22.132\n",
      "-----eval-----  edge_loss:13703.652 psnr:21.791\n",
      "-----train-----  epoch:5 posedge_loss:9135.700 negedge_loss:4236.670 psnr:22.545\n",
      "-----eval-----  edge_loss:13671.392 psnr:21.997\n",
      "-----train-----  epoch:6 posedge_loss:9014.250 negedge_loss:4183.620 psnr:22.917\n",
      "-----eval-----  edge_loss:13595.131 psnr:22.250\n",
      "-----train-----  epoch:7 posedge_loss:8885.140 negedge_loss:4118.970 psnr:23.209\n",
      "-----eval-----  edge_loss:13537.087 psnr:22.471\n",
      "-----train-----  epoch:8 posedge_loss:8792.520 negedge_loss:4062.130 psnr:23.452\n",
      "-----eval-----  edge_loss:13390.522 psnr:22.694\n",
      "-----train-----  epoch:9 posedge_loss:8667.170 negedge_loss:4010.970 psnr:23.719\n",
      "-----eval-----  edge_loss:13381.957 psnr:22.766\n",
      "-----train-----  epoch:10 posedge_loss:8627.189 negedge_loss:3985.020 psnr:23.857\n",
      "-----eval-----  edge_loss:13340.652 psnr:22.876\n",
      "-----train-----  epoch:11 posedge_loss:8519.810 negedge_loss:3927.690 psnr:24.059\n",
      "-----eval-----  edge_loss:13280.479 psnr:23.039\n",
      "-----train-----  epoch:12 posedge_loss:8445.770 negedge_loss:3894.460 psnr:24.232\n",
      "-----eval-----  edge_loss:13268.000 psnr:23.112\n",
      "-----train-----  epoch:13 posedge_loss:8371.590 negedge_loss:3880.880 psnr:24.349\n",
      "-----eval-----  edge_loss:13163.609 psnr:23.206\n",
      "-----train-----  epoch:14 posedge_loss:8282.450 negedge_loss:3843.870 psnr:24.461\n",
      "-----eval-----  edge_loss:13163.783 psnr:23.260\n",
      "-----train-----  epoch:15 posedge_loss:8214.310 negedge_loss:3815.470 psnr:24.557\n",
      "-----eval-----  edge_loss:13086.565 psnr:23.357\n",
      "-----train-----  epoch:16 posedge_loss:8121.890 negedge_loss:3797.350 psnr:24.669\n",
      "-----eval-----  edge_loss:13077.652 psnr:23.371\n",
      "-----train-----  epoch:17 posedge_loss:8028.590 negedge_loss:3771.430 psnr:24.781\n",
      "-----eval-----  edge_loss:13021.174 psnr:23.417\n",
      "-----train-----  epoch:18 posedge_loss:7940.230 negedge_loss:3744.770 psnr:24.855\n",
      "-----eval-----  edge_loss:12948.739 psnr:23.506\n",
      "-----train-----  epoch:19 posedge_loss:7825.330 negedge_loss:3726.090 psnr:24.952\n",
      "-----eval-----  edge_loss:12964.435 psnr:23.508\n",
      "-----train-----  epoch:20 posedge_loss:7818.950 negedge_loss:3723.220 psnr:24.978\n",
      "-----eval-----  edge_loss:12931.870 psnr:23.547\n",
      "-----train-----  epoch:21 posedge_loss:7710.360 negedge_loss:3701.800 psnr:25.062\n",
      "-----eval-----  edge_loss:12904.348 psnr:23.569\n",
      "-----train-----  epoch:22 posedge_loss:7666.720 negedge_loss:3691.940 psnr:25.086\n",
      "-----eval-----  edge_loss:12853.913 psnr:23.600\n",
      "-----train-----  epoch:23 posedge_loss:7581.680 negedge_loss:3678.710 psnr:25.148\n",
      "-----eval-----  edge_loss:12861.783 psnr:23.620\n",
      "-----train-----  epoch:24 posedge_loss:7498.020 negedge_loss:3664.690 psnr:25.193\n",
      "-----eval-----  edge_loss:12825.392 psnr:23.648\n",
      "-----train-----  epoch:25 posedge_loss:7485.780 negedge_loss:3663.450 psnr:25.237\n",
      "-----eval-----  edge_loss:12772.913 psnr:23.657\n",
      "-----train-----  epoch:26 posedge_loss:7386.890 negedge_loss:3643.020 psnr:25.274\n",
      "-----eval-----  edge_loss:12771.131 psnr:23.678\n",
      "-----train-----  epoch:27 posedge_loss:7362.610 negedge_loss:3638.870 psnr:25.304\n",
      "-----eval-----  edge_loss:12757.783 psnr:23.688\n",
      "-----train-----  epoch:28 posedge_loss:7305.450 negedge_loss:3628.290 psnr:25.354\n",
      "-----eval-----  edge_loss:12771.000 psnr:23.684\n",
      "-----train-----  epoch:29 posedge_loss:7274.690 negedge_loss:3626.300 psnr:25.363\n",
      "-----eval-----  edge_loss:12755.044 psnr:23.704\n",
      "-----train-----  epoch:0 posedge_loss:9039.220 negedge_loss:4323.170 psnr:23.137\n",
      "-----eval-----  edge_loss:13518.044 psnr:22.859\n",
      "-----train-----  epoch:1 posedge_loss:8592.939 negedge_loss:4225.650 psnr:23.674\n",
      "-----eval-----  edge_loss:13162.870 psnr:23.156\n",
      "-----train-----  epoch:2 posedge_loss:8293.689 negedge_loss:4108.730 psnr:23.996\n",
      "-----eval-----  edge_loss:12748.479 psnr:23.598\n",
      "-----train-----  epoch:3 posedge_loss:8116.770 negedge_loss:4024.110 psnr:24.312\n",
      "-----eval-----  edge_loss:12507.565 psnr:23.929\n",
      "-----train-----  epoch:4 posedge_loss:7901.750 negedge_loss:3922.550 psnr:24.619\n",
      "-----eval-----  edge_loss:12268.392 psnr:24.144\n",
      "-----train-----  epoch:5 posedge_loss:7693.960 negedge_loss:3841.700 psnr:24.974\n",
      "-----eval-----  edge_loss:12344.957 psnr:24.177\n",
      "-----train-----  epoch:6 posedge_loss:7556.650 negedge_loss:3769.840 psnr:25.206\n",
      "-----eval-----  edge_loss:11975.826 psnr:24.443\n",
      "-----train-----  epoch:7 posedge_loss:7367.430 negedge_loss:3694.590 psnr:25.441\n",
      "-----eval-----  edge_loss:11878.392 psnr:24.659\n",
      "-----train-----  epoch:8 posedge_loss:7222.580 negedge_loss:3633.180 psnr:25.664\n",
      "-----eval-----  edge_loss:11607.826 psnr:24.897\n",
      "-----train-----  epoch:9 posedge_loss:7026.640 negedge_loss:3570.740 psnr:25.895\n",
      "-----eval-----  edge_loss:11461.305 psnr:24.997\n",
      "-----train-----  epoch:10 posedge_loss:6867.420 negedge_loss:3505.740 psnr:26.103\n",
      "-----eval-----  edge_loss:11293.000 psnr:25.136\n",
      "-----train-----  epoch:11 posedge_loss:6598.780 negedge_loss:3437.820 psnr:26.330\n",
      "-----eval-----  edge_loss:11118.435 psnr:25.275\n",
      "-----train-----  epoch:12 posedge_loss:6394.670 negedge_loss:3392.270 psnr:26.493\n",
      "-----eval-----  edge_loss:11075.870 psnr:25.291\n",
      "-----train-----  epoch:13 posedge_loss:6236.830 negedge_loss:3340.280 psnr:26.655\n",
      "-----eval-----  edge_loss:10911.305 psnr:25.423\n",
      "-----train-----  epoch:14 posedge_loss:6005.500 negedge_loss:3296.830 psnr:26.813\n",
      "-----eval-----  edge_loss:10706.479 psnr:25.550\n",
      "-----train-----  epoch:15 posedge_loss:5799.560 negedge_loss:3254.280 psnr:26.938\n",
      "-----eval-----  edge_loss:10540.435 psnr:25.637\n",
      "-----train-----  epoch:16 posedge_loss:5635.590 negedge_loss:3238.570 psnr:27.047\n",
      "-----eval-----  edge_loss:10437.348 psnr:25.661\n",
      "-----train-----  epoch:17 posedge_loss:5488.010 negedge_loss:3193.510 psnr:27.170\n",
      "-----eval-----  edge_loss:10433.174 psnr:25.684\n",
      "-----train-----  epoch:18 posedge_loss:5367.670 negedge_loss:3166.490 psnr:27.243\n",
      "-----eval-----  edge_loss:10277.957 psnr:25.739\n",
      "-----train-----  epoch:19 posedge_loss:5137.790 negedge_loss:3126.720 psnr:27.359\n",
      "-----eval-----  edge_loss:10132.652 psnr:25.779\n",
      "-----train-----  epoch:20 posedge_loss:5069.560 negedge_loss:3115.160 psnr:27.420\n",
      "-----eval-----  edge_loss:10068.826 psnr:25.827\n",
      "-----train-----  epoch:21 posedge_loss:4963.750 negedge_loss:3096.480 psnr:27.500\n",
      "-----eval-----  edge_loss:10066.000 psnr:25.825\n",
      "-----train-----  epoch:22 posedge_loss:4851.250 negedge_loss:3062.910 psnr:27.557\n",
      "-----eval-----  edge_loss:9938.652 psnr:25.866\n",
      "-----train-----  epoch:23 posedge_loss:4760.650 negedge_loss:3063.920 psnr:27.595\n",
      "-----eval-----  edge_loss:9906.652 psnr:25.901\n",
      "-----train-----  epoch:24 posedge_loss:4666.050 negedge_loss:3036.590 psnr:27.666\n",
      "-----eval-----  edge_loss:9835.913 psnr:25.916\n",
      "-----train-----  epoch:25 posedge_loss:4585.230 negedge_loss:3025.310 psnr:27.715\n",
      "-----eval-----  edge_loss:9776.826 psnr:25.966\n",
      "-----train-----  epoch:26 posedge_loss:4488.030 negedge_loss:3008.050 psnr:27.777\n",
      "-----eval-----  edge_loss:9752.479 psnr:25.970\n",
      "-----train-----  epoch:27 posedge_loss:4455.810 negedge_loss:2992.190 psnr:27.813\n",
      "-----eval-----  edge_loss:9682.131 psnr:25.994\n",
      "-----train-----  epoch:28 posedge_loss:4417.940 negedge_loss:2986.110 psnr:27.839\n",
      "-----eval-----  edge_loss:9699.261 psnr:25.990\n",
      "-----train-----  epoch:29 posedge_loss:4356.400 negedge_loss:2970.920 psnr:27.882\n",
      "-----eval-----  edge_loss:9628.305 psnr:26.003\n",
      "-----train-----  epoch:0 posedge_loss:8494.060 negedge_loss:4173.410 psnr:23.664\n",
      "-----eval-----  edge_loss:13046.435 psnr:23.122\n",
      "-----train-----  epoch:1 posedge_loss:8313.260 negedge_loss:4133.200 psnr:23.783\n",
      "-----eval-----  edge_loss:12788.261 psnr:23.371\n",
      "-----train-----  epoch:2 posedge_loss:8120.250 negedge_loss:4071.260 psnr:24.065\n",
      "-----eval-----  edge_loss:12589.000 psnr:23.489\n",
      "-----train-----  epoch:3 posedge_loss:8018.190 negedge_loss:4032.960 psnr:24.128\n",
      "-----eval-----  edge_loss:12475.652 psnr:23.558\n",
      "-----train-----  epoch:4 posedge_loss:7792.980 negedge_loss:3919.910 psnr:24.532\n",
      "-----eval-----  edge_loss:12232.479 psnr:23.953\n",
      "-----train-----  epoch:5 posedge_loss:7572.370 negedge_loss:3830.270 psnr:24.881\n",
      "-----eval-----  edge_loss:11801.131 psnr:24.411\n",
      "-----train-----  epoch:6 posedge_loss:7315.010 negedge_loss:3725.260 psnr:25.283\n",
      "-----eval-----  edge_loss:11666.913 psnr:24.620\n",
      "-----train-----  epoch:7 posedge_loss:7135.880 negedge_loss:3636.420 psnr:25.542\n",
      "-----eval-----  edge_loss:11411.392 psnr:24.858\n",
      "-----train-----  epoch:8 posedge_loss:6962.450 negedge_loss:3567.830 psnr:25.800\n",
      "-----eval-----  edge_loss:11039.521 psnr:25.092\n",
      "-----train-----  epoch:9 posedge_loss:6709.290 negedge_loss:3488.500 psnr:26.106\n",
      "-----eval-----  edge_loss:10950.087 psnr:25.222\n",
      "-----train-----  epoch:10 posedge_loss:6463.430 negedge_loss:3415.220 psnr:26.344\n",
      "-----eval-----  edge_loss:10595.218 psnr:25.474\n",
      "-----train-----  epoch:11 posedge_loss:6240.770 negedge_loss:3340.290 psnr:26.606\n",
      "-----eval-----  edge_loss:10588.392 psnr:25.520\n",
      "-----train-----  epoch:12 posedge_loss:6058.410 negedge_loss:3297.720 psnr:26.770\n",
      "-----eval-----  edge_loss:10258.609 psnr:25.702\n",
      "-----train-----  epoch:13 posedge_loss:5793.150 negedge_loss:3229.850 psnr:27.002\n",
      "-----eval-----  edge_loss:10286.609 psnr:25.758\n",
      "-----train-----  epoch:14 posedge_loss:5672.410 negedge_loss:3209.260 psnr:27.101\n",
      "-----eval-----  edge_loss:10092.652 psnr:25.867\n",
      "-----train-----  epoch:15 posedge_loss:5390.110 negedge_loss:3135.540 psnr:27.290\n",
      "-----eval-----  edge_loss:9881.435 psnr:25.958\n",
      "-----train-----  epoch:16 posedge_loss:5224.390 negedge_loss:3103.400 psnr:27.416\n",
      "-----eval-----  edge_loss:9707.305 psnr:26.079\n",
      "-----train-----  epoch:17 posedge_loss:4974.490 negedge_loss:3052.540 psnr:27.574\n",
      "-----eval-----  edge_loss:9400.608 psnr:26.125\n",
      "-----train-----  epoch:18 posedge_loss:4777.540 negedge_loss:3015.180 psnr:27.670\n",
      "-----eval-----  edge_loss:9479.565 psnr:26.161\n",
      "-----train-----  epoch:19 posedge_loss:4694.270 negedge_loss:2991.670 psnr:27.767\n",
      "-----eval-----  edge_loss:9112.913 psnr:26.229\n",
      "-----train-----  epoch:20 posedge_loss:4462.100 negedge_loss:2940.940 psnr:27.891\n",
      "-----eval-----  edge_loss:9047.174 psnr:26.290\n",
      "-----train-----  epoch:21 posedge_loss:4250.480 negedge_loss:2905.420 psnr:28.004\n",
      "-----eval-----  edge_loss:8918.348 psnr:26.323\n",
      "-----train-----  epoch:22 posedge_loss:4161.200 negedge_loss:2894.700 psnr:28.067\n",
      "-----eval-----  edge_loss:8824.870 psnr:26.370\n",
      "-----train-----  epoch:23 posedge_loss:4048.960 negedge_loss:2862.250 psnr:28.129\n",
      "-----eval-----  edge_loss:8715.044 psnr:26.404\n",
      "-----train-----  epoch:24 posedge_loss:4009.480 negedge_loss:2843.650 psnr:28.190\n",
      "-----eval-----  edge_loss:8651.739 psnr:26.445\n",
      "-----train-----  epoch:25 posedge_loss:3919.880 negedge_loss:2821.940 psnr:28.258\n",
      "-----eval-----  edge_loss:8598.957 psnr:26.439\n",
      "-----train-----  epoch:26 posedge_loss:3824.840 negedge_loss:2789.490 psnr:28.315\n",
      "-----eval-----  edge_loss:8499.479 psnr:26.492\n",
      "-----train-----  epoch:27 posedge_loss:3793.540 negedge_loss:2783.220 psnr:28.359\n",
      "-----eval-----  edge_loss:8503.870 psnr:26.479\n",
      "-----train-----  epoch:28 posedge_loss:3731.350 negedge_loss:2764.960 psnr:28.404\n",
      "-----eval-----  edge_loss:8497.131 psnr:26.501\n",
      "-----train-----  epoch:29 posedge_loss:3697.080 negedge_loss:2753.020 psnr:28.454\n",
      "-----eval-----  edge_loss:8435.000 psnr:26.502\n",
      "-----eval-----  edge_loss:8434.957 psnr:26.502\n",
      "Training time: 557.67 s\n",
      "Rendering quality: 26.50 dB\n",
      "Rendering speed: 97.82 fps\n",
      "Model size: 7.91 MB\n"
     ]
    }
   ],
   "source": [
    "# MATERIALS new\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname materials --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.03 --splatting_r 0.010 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6392212b-a16e-4a45-98b5-8a7146b1e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# MIC\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname mic --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.15 --splatting_r 0.008 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0785b53e-0100-4b8d-a640-6ea8e8162f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  Tesla V100-PCIE-32GB\n",
      "Are we using ms-ssim loss?  True\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  True\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.44it/s]\n",
      "Initialization, data:ficus point:(261429, 6)\n",
      "imagegt shape:  torch.Size([400, 400, 400, 3])\n",
      "Using splatting_r:  0.008\n",
      "Using data_r:  0.15\n",
      "Initialized point number:39214\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/ficus/v2_0.150_0.008/msssimTruedistsFalseedgesTrueadaptive_splattingrFalseadaptive_datarFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 posedge_loss:2912.850 negedge_loss:4375.300 psnr:24.429\n",
      "-----eval-----  edge_loss:7253.043 psnr:24.938\n",
      "-----train-----  epoch:1 posedge_loss:3439.610 negedge_loss:3446.800 psnr:25.449\n",
      "-----eval-----  edge_loss:7111.174 psnr:25.266\n",
      "-----train-----  epoch:2 posedge_loss:3547.110 negedge_loss:3227.310 psnr:25.711\n",
      "-----eval-----  edge_loss:7073.392 psnr:25.428\n",
      "-----train-----  epoch:3 posedge_loss:3543.030 negedge_loss:3127.800 psnr:25.836\n",
      "-----eval-----  edge_loss:7062.261 psnr:25.423\n",
      "-----train-----  epoch:4 posedge_loss:3575.970 negedge_loss:3077.460 psnr:25.896\n",
      "-----eval-----  edge_loss:6925.435 psnr:25.554\n",
      "-----train-----  epoch:5 posedge_loss:3576.460 negedge_loss:3025.790 psnr:25.950\n",
      "-----eval-----  edge_loss:6889.957 psnr:25.611\n",
      "-----train-----  epoch:6 posedge_loss:3545.360 negedge_loss:2985.110 psnr:26.020\n",
      "-----eval-----  edge_loss:6940.783 psnr:25.547\n",
      "-----train-----  epoch:7 posedge_loss:3532.880 negedge_loss:2953.650 psnr:26.081\n",
      "-----eval-----  edge_loss:6858.739 psnr:25.643\n",
      "-----train-----  epoch:8 posedge_loss:3520.630 negedge_loss:2908.880 psnr:26.158\n",
      "-----eval-----  edge_loss:6821.087 psnr:25.681\n",
      "-----train-----  epoch:9 posedge_loss:3493.910 negedge_loss:2882.020 psnr:26.210\n",
      "-----eval-----  edge_loss:6806.043 psnr:25.702\n",
      "-----train-----  epoch:10 posedge_loss:3482.940 negedge_loss:2864.500 psnr:26.255\n",
      "-----eval-----  edge_loss:6776.479 psnr:25.708\n",
      "-----train-----  epoch:11 posedge_loss:3458.780 negedge_loss:2830.070 psnr:26.310\n",
      "-----eval-----  edge_loss:6759.957 psnr:25.734\n",
      "-----train-----  epoch:12 posedge_loss:3456.310 negedge_loss:2821.080 psnr:26.336\n",
      "-----eval-----  edge_loss:6739.043 psnr:25.758\n",
      "-----train-----  epoch:13 posedge_loss:3438.640 negedge_loss:2791.770 psnr:26.375\n",
      "-----eval-----  edge_loss:6654.348 psnr:25.841\n",
      "-----train-----  epoch:14 posedge_loss:3423.740 negedge_loss:2786.150 psnr:26.406\n",
      "-----eval-----  edge_loss:6694.870 psnr:25.793\n",
      "-----train-----  epoch:15 posedge_loss:3401.530 negedge_loss:2765.180 psnr:26.439\n",
      "-----eval-----  edge_loss:6664.565 psnr:25.834\n",
      "-----train-----  epoch:16 posedge_loss:3404.650 negedge_loss:2752.870 psnr:26.452\n",
      "-----eval-----  edge_loss:6657.130 psnr:25.848\n",
      "-----train-----  epoch:17 posedge_loss:3387.280 negedge_loss:2738.670 psnr:26.495\n",
      "-----eval-----  edge_loss:6684.348 psnr:25.812\n",
      "-----train-----  epoch:18 posedge_loss:3387.840 negedge_loss:2734.180 psnr:26.498\n",
      "-----eval-----  edge_loss:6647.957 psnr:25.839\n",
      "-----train-----  epoch:19 posedge_loss:3363.930 negedge_loss:2720.620 psnr:26.532\n",
      "-----eval-----  edge_loss:6640.348 psnr:25.817\n",
      "-----train-----  epoch:0 posedge_loss:4562.210 negedge_loss:3688.370 psnr:18.831\n",
      "-----eval-----  edge_loss:8446.305 psnr:19.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FICUS\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname ficus --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.15 --splatting_r 0.008 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fbd4f-b54c-49cd-983d-493a26b6acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRUMS\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname drums --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.25 --splatting_r 0.008 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c30e6-9777-4555-8e87-7013a2e1d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAIR\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname drums --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.25 --splatting_r 0.008 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0d03b-da59-449b-ac4a-6261bf6e6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHIP\n",
    "!python main.py --datadir /scratch/network/by7705/cos526/nerf_synthetic --dataname ship --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.03 --splatting_r 0.010 --use_msssim True --use_dists False --use_edges True --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196ff57-69d8-4718-a4cc-f4887b721d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['lego','materials','mic','ficus','drums','chair','ship','hotdog']\n",
    "data_r_mapping = {'hotdog':0.012,'lego':0.08,'materials':0.03,'mic':0.15,'ficus':0.15,'drums':0.25,'chair':0.06,'ship':0.03}\n",
    "splatting_mapping = {'hotdog':0.015,'lego':0.010,'materials':0.010,'mic':0.008,'ficus':0.008,'drums':0.008,'chair':0.010,'ship':0.010}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fc9d3-790c-4247-a224-35c3b326aa59",
   "metadata": {},
   "source": [
    "# EXPERIMENTS (LLFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df7e81d-6c76-49f6-88a7-766327ed4db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda:0\n",
      "Are we using ms-ssim loss?  False\n",
      "Are we using DISTS loss?  False\n",
      "Are we using edges loss?  False\n",
      "Are we using adaptive splatting_r selection?  False\n",
      "Are we using adaptive adaptive_datar selection?  False\n",
      "i_split:  [array([ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 17, 18, 19]), array([ 0,  8, 16]), array([ 0,  8, 16])]\n",
      "  0%|                                                   | 0/756 [00:00<?, ?it/s]/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643016022/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 756/756 [00:11<00:00, 64.73it/s]\n",
      "Initialization, data:fern point:(21427711, 6)\n",
      "imagegt shape:  torch.Size([20, 756, 1008, 3])\n",
      "Using splatting_r:  0.001\n",
      "Using data_r:  0.08\n",
      "Initialized point number:1714216\n",
      "/scratch/network/by7705/cos526/point-radiance/logs/output/images/fern/v2_0.080_0.001/msssimFalsedistsFalseedgesFalseadaptive_splattingrFalseadaptive_datarFalse\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/by7705/.conda/envs/pytorch3d/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "-----train-----  epoch:0 loss:0.270 psnr:5.824\n",
      "-----eval-----  loss:0.265 psnr:5.776\n",
      "-----train-----  epoch:1 loss:0.269 psnr:5.840\n",
      "-----eval-----  loss:0.264 psnr:5.786\n",
      "-----train-----  epoch:2 loss:0.267 psnr:5.872\n",
      "-----eval-----  loss:0.263 psnr:5.798\n",
      "-----train-----  epoch:3 loss:0.268 psnr:5.862\n",
      "-----eval-----  loss:0.263 psnr:5.806\n",
      "-----train-----  epoch:4 loss:0.267 psnr:5.885\n",
      "-----eval-----  loss:0.262 psnr:5.813\n",
      "-----train-----  epoch:5 loss:0.267 psnr:5.880\n",
      "-----eval-----  loss:0.262 psnr:5.817\n",
      "-----train-----  epoch:6 loss:0.265 psnr:5.910\n",
      "-----eval-----  loss:0.262 psnr:5.823\n",
      "-----train-----  epoch:7 loss:0.266 psnr:5.905\n",
      "-----eval-----  loss:0.262 psnr:5.827\n",
      "-----train-----  epoch:8 loss:0.265 psnr:5.909\n",
      "-----eval-----  loss:0.261 psnr:5.834\n",
      "-----train-----  epoch:9 loss:0.264 psnr:5.924\n",
      "-----eval-----  loss:0.261 psnr:5.834\n",
      "-----train-----  epoch:10 loss:0.264 psnr:5.941\n",
      "-----eval-----  loss:0.261 psnr:5.837\n",
      "-----train-----  epoch:11 loss:0.263 psnr:5.945\n",
      "-----eval-----  loss:0.261 psnr:5.841\n",
      "-----train-----  epoch:12 loss:0.262 psnr:5.961\n",
      "-----eval-----  loss:0.261 psnr:5.843\n",
      "-----train-----  epoch:13 loss:0.261 psnr:5.983\n",
      "-----eval-----  loss:0.261 psnr:5.845\n",
      "-----train-----  epoch:14 loss:0.261 psnr:5.983\n",
      "-----eval-----  loss:0.260 psnr:5.847\n",
      "-----train-----  epoch:15 loss:0.260 psnr:6.005\n",
      "-----eval-----  loss:0.260 psnr:5.848\n",
      "-----train-----  epoch:16 loss:0.259 psnr:6.014\n",
      "-----eval-----  loss:0.260 psnr:5.849\n",
      "-----train-----  epoch:17 loss:0.258 psnr:6.035\n",
      "-----eval-----  loss:0.260 psnr:5.852\n",
      "-----train-----  epoch:18 loss:0.257 psnr:6.047\n",
      "-----eval-----  loss:0.260 psnr:5.851\n",
      "-----train-----  epoch:19 loss:0.255 psnr:6.079\n",
      "-----eval-----  loss:0.260 psnr:5.853\n",
      "-----train-----  epoch:0 loss:0.275 psnr:5.790\n",
      "-----eval-----  loss:0.265 psnr:5.773\n",
      "-----train-----  epoch:1 loss:0.268 psnr:5.892\n",
      "-----eval-----  loss:0.262 psnr:5.826\n",
      "-----train-----  epoch:2 loss:0.264 psnr:5.942\n",
      "-----eval-----  loss:0.261 psnr:5.845\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# FERN NEW\n",
    "!python main.py --dataset_type llff --datadir /scratch/network/by7705/cos526/nerf_llff_data --dataname fern --img_h 756 --img_w 1008 --factor 4 --llffhold 8 --basedir /scratch/network/by7705/cos526/point-radiance/logs --data_r 0.08 --splatting_r 0.001 --use_msssim False --use_dists False --use_edges False --adaptive_splattingr False --adaptive_datar False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b392a4-96c2-4c18-8a75-e38bee3da18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('pytorch3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "79374b9ac58d3a955aec63c7189c945418e89f241bc62099820228ac996d0e3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
